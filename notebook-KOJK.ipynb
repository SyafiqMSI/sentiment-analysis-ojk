{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "os.makedirs(r'C:\\\\nltk_data', exist_ok=True)\n",
    "nltk.data.path.append(r'C:\\\\nltk_data')  \n",
    "nltk.download('punkt_tab', download_dir=r'C:\\\\nltk_data')\n",
    "nltk.download('stopwords', download_dir=r'C:\\\\nltk_data')\n",
    "nltk.download('wordnet', download_dir=r'C:\\\\nltk_data')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Dataset                      ID BIDANG SATKER (AKRONIM)  \\\n",
      "0      DATABASE KOJK EMAIL  EKSTERNAL_KOJK_EMAIL_1     KS       KR1 - KOJT   \n",
      "1      DATABASE KOJK EMAIL  EKSTERNAL_KOJK_EMAIL_2     KS       KR1 - KOJT   \n",
      "2      DATABASE KOJK EMAIL  EKSTERNAL_KOJK_EMAIL_3     KS       KR1 - KOJT   \n",
      "3      DATABASE KOJK EMAIL  EKSTERNAL_KOJK_EMAIL_4     KS       KR1 - KOJT   \n",
      "4      DATABASE KOJK EMAIL  EKSTERNAL_KOJK_EMAIL_5     KS       KR1 - KOJT   \n",
      "...                    ...                     ...    ...              ...   \n",
      "20582  DATABASE KOJK NO HP  EKSTERNAL_KOJK_HP_5235     KS       KR3 - KOSG   \n",
      "20583  DATABASE KOJK NO HP  EKSTERNAL_KOJK_HP_5236     KS       KR3 - KOSG   \n",
      "20584  DATABASE KOJK NO HP  EKSTERNAL_KOJK_HP_5237     KS       KR3 - KOSG   \n",
      "20585  DATABASE KOJK NO HP  EKSTERNAL_KOJK_HP_5238     KS       KR3 - KOSG   \n",
      "20586  DATABASE KOJK NO HP  EKSTERNAL_KOJK_HP_5239     KS       KR3 - KOSG   \n",
      "\n",
      "       JENIS SURVEI                           TIPE QUESTION  \\\n",
      "0      NON INTERNAL                     PENGAWASAN LANGSUNG   \n",
      "1      NON INTERNAL                     PENGAWASAN LANGSUNG   \n",
      "2      NON INTERNAL                     PENGAWASAN LANGSUNG   \n",
      "3      NON INTERNAL                     PENGAWASAN LANGSUNG   \n",
      "4      NON INTERNAL                     PENGAWASAN LANGSUNG   \n",
      "...             ...                                     ...   \n",
      "20582  NON INTERNAL  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "20583  NON INTERNAL  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "20584  NON INTERNAL  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "20585  NON INTERNAL  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "20586  NON INTERNAL  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "\n",
      "      INSTITUSI / PERSEORANGAN/ASAL SATKER       RESPOND LINK SURVEYMONKEY  \\\n",
      "0                              PT Bank DKI  BELUM DI ISI        LOGIC KOJK   \n",
      "1                      PT BPR Puspita Sari  BELUM DI ISI        LOGIC KOJK   \n",
      "2                 PT BPR Brilian Investama  BELUM DI ISI        LOGIC KOJK   \n",
      "3                 PT BPR Gita Makmur Utama  BELUM DI ISI        LOGIC KOJK   \n",
      "4                     PT BPR Darbeni Rizki  BELUM DI ISI        LOGIC KOJK   \n",
      "...                                    ...           ...               ...   \n",
      "20582              MARGARETA DIANA SAPUTRI  SUDAH DI ISI         KOJK HP 1   \n",
      "20583                    Irsyad Akmal Fata  BELUM DI ISI         KOJK HP 1   \n",
      "20584               Evrillyo Andea Gunawan  BELUM DI ISI         KOJK HP 1   \n",
      "20585      Muhammad Nashrul Muhtaril Fajar  BELUM DI ISI         KOJK HP 1   \n",
      "20586                   Saka Ardika Kusuma  BELUM DI ISI         KOJK HP 1   \n",
      "\n",
      "       WEBLINK SURVEYMONKEY  ...  INTEREST KATEGORI DATE Unnamed: 23  \\\n",
      "0                       NaN  ...      HIGH   PLAYER  NaN         NaN   \n",
      "1                       NaN  ...      HIGH   PLAYER  NaN         NaN   \n",
      "2                       NaN  ...      HIGH   PLAYER  NaN         NaN   \n",
      "3                       NaN  ...      HIGH   PLAYER  NaN         NaN   \n",
      "4                       NaN  ...      HIGH   PLAYER  NaN         NaN   \n",
      "...                     ...  ...       ...      ...  ...         ...   \n",
      "20582                   NaN  ...      HIGH   PLAYER  NaN         NaN   \n",
      "20583                   NaN  ...      HIGH   PLAYER  NaN         NaN   \n",
      "20584                   NaN  ...      HIGH   PLAYER  NaN         NaN   \n",
      "20585                   NaN  ...      HIGH   PLAYER  NaN         NaN   \n",
      "20586                   NaN  ...      HIGH   PLAYER  NaN         NaN   \n",
      "\n",
      "      RESOURCE PERCEPTION PERFORMANCE DELIVERY OS PENTING OS PUAS  \\\n",
      "0                     NaN                  NaN        NaN     NaN   \n",
      "1                     NaN                  NaN        NaN     NaN   \n",
      "2                     NaN                  NaN        NaN     NaN   \n",
      "3                     NaN                  NaN        NaN     NaN   \n",
      "4                     NaN                  NaN        NaN     NaN   \n",
      "...                   ...                  ...        ...     ...   \n",
      "20582                   6                    6          6       6   \n",
      "20583                 NaN                  NaN        NaN     NaN   \n",
      "20584                 NaN                  NaN        NaN     NaN   \n",
      "20585                 NaN                  NaN        NaN     NaN   \n",
      "20586                 NaN                  NaN        NaN     NaN   \n",
      "\n",
      "                                         OPEN QUESTION 1  \\\n",
      "0                                                    NaN   \n",
      "1                                                    NaN   \n",
      "2                                                    NaN   \n",
      "3                                                    NaN   \n",
      "4                                                    NaN   \n",
      "...                                                  ...   \n",
      "20582  Pelaksanaan kegiatan edukasi dan literasi keua...   \n",
      "20583                                                NaN   \n",
      "20584                                                NaN   \n",
      "20585                                                NaN   \n",
      "20586                                                NaN   \n",
      "\n",
      "                                         OPEN QUESTION 2  \n",
      "0                                                    NaN  \n",
      "1                                                    NaN  \n",
      "2                                                    NaN  \n",
      "3                                                    NaN  \n",
      "4                                                    NaN  \n",
      "...                                                  ...  \n",
      "20582  Saran untuk meningkatkan kegiatan edukasi dan ...  \n",
      "20583                                                NaN  \n",
      "20584                                                NaN  \n",
      "20585                                                NaN  \n",
      "20586                                                NaN  \n",
      "\n",
      "[20587 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_database_result_csv(file_path):\n",
    "    try:\n",
    "        # Mencoba membaca dengan encoding default (utf-8) dan delimiter koma\n",
    "        df = pd.read_csv(file_path, sep=';', encoding='utf-8')\n",
    "    except UnicodeDecodeError as e1:\n",
    "        try:\n",
    "            # Jika gagal, mencoba dengan encoding latin1\n",
    "            df = pd.read_csv(file_path, sep=';', encoding='latin1')\n",
    "        except UnicodeDecodeError as e2:\n",
    "            try:\n",
    "                # Jika gagal, mencoba dengan encoding cp1252\n",
    "                df = pd.read_csv(file_path, sep=';', encoding='cp1252')\n",
    "            except Exception as e3:\n",
    "                print(f\"Gagal membaca file {file_path}: {e1} | {e2} | {e3}\")\n",
    "                return pd.DataFrame()  # Mengembalikan DataFrame kosong jika gagal\n",
    "    return df\n",
    "\n",
    "# Path ke file DATABASE_RESULT_OJK.csv\n",
    "file_path = 'data/main_data_28_KOJK.csv'\n",
    "database_result_df = read_database_result_csv(file_path)\n",
    "\n",
    "print(database_result_df)\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# def read_database_result_excel(file_path):\n",
    "#     try:\n",
    "#         # Membaca file Excel\n",
    "#         df = pd.read_excel(file_path, engine='openpyxl')\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"File tidak ditemukan: {file_path}\")\n",
    "#         return pd.DataFrame()  # Mengembalikan DataFrame kosong jika file tidak ditemukan\n",
    "#     except Exception as e:\n",
    "#         print(f\"Gagal membaca file Excel {file_path}: {e}\")\n",
    "#         return pd.DataFrame()  # Mengembalikan DataFrame kosong jika gagal membaca\n",
    "#     return df\n",
    "\n",
    "# # Path ke file DATABASE_RESULT_OJK.xlsx\n",
    "# file_path = 'DATABASE BESAR OJK X FINTECH UNS.xlsx'\n",
    "# database_result_df = read_database_result_excel(file_path)\n",
    "\n",
    "# print(database_result_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #FILTERING SATKER\n",
    "\n",
    "# # Menentukan filter SATKER yang diinginkan\n",
    "# filter_option = input(\"Apakah Anda ingin memilih SATKER berdasarkan pilihan tertentu (y/n)? \")\n",
    "\n",
    "# if filter_option.lower() == 'y':\n",
    "#     # Jika pengguna memilih untuk memasukkan SATKER\n",
    "#     selected_satker = input(\"Masukkan SATKER yang ingin difilter (misal: 'DPEA'): \")\n",
    "    \n",
    "#     # Memfilter data berdasarkan SATKER yang dipilih\n",
    "#     filtered_df = database_result_df[database_result_df['SATKER (AKRONIM)'] == selected_satker]\n",
    "#     print(f\"Data difilter berdasarkan SATKER: {selected_satker}\")\n",
    "    \n",
    "# elif filter_option.lower() == 'n':\n",
    "#     # Jika pengguna memilih untuk memfilter berdasarkan beberapa SATKER tertentu\n",
    "#     selected_satker_list = ['DPEA', 'DOSB', 'DPSI']  # Contoh daftar SATKER yang bisa dipilih\n",
    "#     filtered_df = database_result_df[database_result_df['SATKER (AKRONIM)'].isin(selected_satker_list)]\n",
    "#     print(f\"Data difilter berdasarkan beberapa SATKER: {', '.join(selected_satker_list)}\")\n",
    "    \n",
    "# else:\n",
    "#     # Jika input selain 'y' atau 'n', tampilkan pesan\n",
    "#     print(\"Pilihan tidak valid. Menggunakan data tanpa filter.\")\n",
    "#     filtered_df = database_result_df\n",
    "\n",
    "# # Menampilkan data yang sudah difilter\n",
    "# print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(database_result_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop = database_result_df.drop(index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order = [\n",
    "    'ID','BIDANG','SATKER (AKRONIM)','JENIS SURVEI','TIPE QUESTION','INSTITUSI / PERSEORANGAN/ASAL SATKER','RESPOND','LINK SURVEYMONKEY','TOKEN','NAMA PIC/RESPONDEN','JABATAN/PROFESI/LVEL DI OJK','KONTAK','FUNGSI YANG DINILAI','DIRECT / INDIRECT','JENIS STAKEHOLDERS','RELASI RESPONDEN DENGAN SATKER','POWER','INTEREST','KATEGORI','Dataset','RESOURCE PERCEPTION','PERFORMANCE DELIVERY','OPEN QUESTION 1','OPEN QUESTION 2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_kojk_df = database_result_df[columns_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           ID BIDANG SATKER (AKRONIM)  JENIS SURVEI  \\\n",
      "0      EKSTERNAL_KOJK_EMAIL_1     KS       KR1 - KOJT  NON INTERNAL   \n",
      "1      EKSTERNAL_KOJK_EMAIL_2     KS       KR1 - KOJT  NON INTERNAL   \n",
      "2      EKSTERNAL_KOJK_EMAIL_3     KS       KR1 - KOJT  NON INTERNAL   \n",
      "3      EKSTERNAL_KOJK_EMAIL_4     KS       KR1 - KOJT  NON INTERNAL   \n",
      "4      EKSTERNAL_KOJK_EMAIL_5     KS       KR1 - KOJT  NON INTERNAL   \n",
      "...                       ...    ...              ...           ...   \n",
      "20582  EKSTERNAL_KOJK_HP_5235     KS       KR3 - KOSG  NON INTERNAL   \n",
      "20583  EKSTERNAL_KOJK_HP_5236     KS       KR3 - KOSG  NON INTERNAL   \n",
      "20584  EKSTERNAL_KOJK_HP_5237     KS       KR3 - KOSG  NON INTERNAL   \n",
      "20585  EKSTERNAL_KOJK_HP_5238     KS       KR3 - KOSG  NON INTERNAL   \n",
      "20586  EKSTERNAL_KOJK_HP_5239     KS       KR3 - KOSG  NON INTERNAL   \n",
      "\n",
      "                                TIPE QUESTION  \\\n",
      "0                         PENGAWASAN LANGSUNG   \n",
      "1                         PENGAWASAN LANGSUNG   \n",
      "2                         PENGAWASAN LANGSUNG   \n",
      "3                         PENGAWASAN LANGSUNG   \n",
      "4                         PENGAWASAN LANGSUNG   \n",
      "...                                       ...   \n",
      "20582  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "20583  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "20584  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "20585  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "20586  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "\n",
      "      INSTITUSI / PERSEORANGAN/ASAL SATKER       RESPOND LINK SURVEYMONKEY  \\\n",
      "0                              PT Bank DKI  BELUM DI ISI        LOGIC KOJK   \n",
      "1                      PT BPR Puspita Sari  BELUM DI ISI        LOGIC KOJK   \n",
      "2                 PT BPR Brilian Investama  BELUM DI ISI        LOGIC KOJK   \n",
      "3                 PT BPR Gita Makmur Utama  BELUM DI ISI        LOGIC KOJK   \n",
      "4                     PT BPR Darbeni Rizki  BELUM DI ISI        LOGIC KOJK   \n",
      "...                                    ...           ...               ...   \n",
      "20582              MARGARETA DIANA SAPUTRI  SUDAH DI ISI         KOJK HP 1   \n",
      "20583                    Irsyad Akmal Fata  BELUM DI ISI         KOJK HP 1   \n",
      "20584               Evrillyo Andea Gunawan  BELUM DI ISI         KOJK HP 1   \n",
      "20585      Muhammad Nashrul Muhtaril Fajar  BELUM DI ISI         KOJK HP 1   \n",
      "20586                   Saka Ardika Kusuma  BELUM DI ISI         KOJK HP 1   \n",
      "\n",
      "       TOKEN               NAMA PIC/RESPONDEN  ...  \\\n",
      "0         23                      Ateng Rivai  ...   \n",
      "1         23                            Yayuk  ...   \n",
      "2         23                        Syukirman  ...   \n",
      "3         23                    Lisa Andriani  ...   \n",
      "4         20                    Agung Riyanto  ...   \n",
      "...      ...                              ...  ...   \n",
      "20582      4          MARGARETA DIANA SAPUTRI  ...   \n",
      "20583      4                Irsyad Akmal Fata  ...   \n",
      "20584      4           Evrillyo Andea Gunawan  ...   \n",
      "20585      4  Muhammad Nashrul Muhtaril Fajar  ...   \n",
      "20586      4               Saka Ardika Kusuma  ...   \n",
      "\n",
      "                 JENIS STAKEHOLDERS RELASI RESPONDEN DENGAN SATKER POWER  \\\n",
      "0                        BU/BUS/BPD               LJK YANG DIAWASI  HIGH   \n",
      "1                               BPR               LJK YANG DIAWASI  HIGH   \n",
      "2                               BPR               LJK YANG DIAWASI  HIGH   \n",
      "3                               BPR               LJK YANG DIAWASI  HIGH   \n",
      "4                               BPR               LJK YANG DIAWASI  HIGH   \n",
      "...                             ...                            ...   ...   \n",
      "20582  UNIVERSITAS/PERGURUAN TINGGI   UNIVERSITAS/PERGURUAN TINGGI  HIGH   \n",
      "20583  UNIVERSITAS/PERGURUAN TINGGI   UNIVERSITAS/PERGURUAN TINGGI  HIGH   \n",
      "20584  UNIVERSITAS/PERGURUAN TINGGI   UNIVERSITAS/PERGURUAN TINGGI  HIGH   \n",
      "20585  UNIVERSITAS/PERGURUAN TINGGI   UNIVERSITAS/PERGURUAN TINGGI  HIGH   \n",
      "20586  UNIVERSITAS/PERGURUAN TINGGI   UNIVERSITAS/PERGURUAN TINGGI  HIGH   \n",
      "\n",
      "      INTEREST KATEGORI              Dataset RESOURCE PERCEPTION  \\\n",
      "0         HIGH   PLAYER  DATABASE KOJK EMAIL                 NaN   \n",
      "1         HIGH   PLAYER  DATABASE KOJK EMAIL                 NaN   \n",
      "2         HIGH   PLAYER  DATABASE KOJK EMAIL                 NaN   \n",
      "3         HIGH   PLAYER  DATABASE KOJK EMAIL                 NaN   \n",
      "4         HIGH   PLAYER  DATABASE KOJK EMAIL                 NaN   \n",
      "...        ...      ...                  ...                 ...   \n",
      "20582     HIGH   PLAYER  DATABASE KOJK NO HP                   6   \n",
      "20583     HIGH   PLAYER  DATABASE KOJK NO HP                 NaN   \n",
      "20584     HIGH   PLAYER  DATABASE KOJK NO HP                 NaN   \n",
      "20585     HIGH   PLAYER  DATABASE KOJK NO HP                 NaN   \n",
      "20586     HIGH   PLAYER  DATABASE KOJK NO HP                 NaN   \n",
      "\n",
      "      PERFORMANCE DELIVERY                                    OPEN QUESTION 1  \\\n",
      "0                      NaN                                                NaN   \n",
      "1                      NaN                                                NaN   \n",
      "2                      NaN                                                NaN   \n",
      "3                      NaN                                                NaN   \n",
      "4                      NaN                                                NaN   \n",
      "...                    ...                                                ...   \n",
      "20582                    6  Pelaksanaan kegiatan edukasi dan literasi keua...   \n",
      "20583                  NaN                                                NaN   \n",
      "20584                  NaN                                                NaN   \n",
      "20585                  NaN                                                NaN   \n",
      "20586                  NaN                                                NaN   \n",
      "\n",
      "                                         OPEN QUESTION 2  \n",
      "0                                                    NaN  \n",
      "1                                                    NaN  \n",
      "2                                                    NaN  \n",
      "3                                                    NaN  \n",
      "4                                                    NaN  \n",
      "...                                                  ...  \n",
      "20582  Saran untuk meningkatkan kegiatan edukasi dan ...  \n",
      "20583                                                NaN  \n",
      "20584                                                NaN  \n",
      "20585                                                NaN  \n",
      "20586                                                NaN  \n",
      "\n",
      "[20587 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_data_kojk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                          0\n",
      "BIDANG                                      0\n",
      "SATKER (AKRONIM)                            0\n",
      "JENIS SURVEI                                0\n",
      "TIPE QUESTION                               0\n",
      "INSTITUSI / PERSEORANGAN/ASAL SATKER        0\n",
      "RESPOND                                     0\n",
      "LINK SURVEYMONKEY                           0\n",
      "TOKEN                                       0\n",
      "NAMA PIC/RESPONDEN                        109\n",
      "JABATAN/PROFESI/LVEL DI OJK              2777\n",
      "KONTAK                                   2734\n",
      "FUNGSI YANG DINILAI                         0\n",
      "DIRECT / INDIRECT                           0\n",
      "JENIS STAKEHOLDERS                         21\n",
      "RELASI RESPONDEN DENGAN SATKER          10749\n",
      "POWER                                       0\n",
      "INTEREST                                    0\n",
      "KATEGORI                                    0\n",
      "Dataset                                     0\n",
      "RESOURCE PERCEPTION                     18999\n",
      "PERFORMANCE DELIVERY                    18999\n",
      "OPEN QUESTION 1                         18505\n",
      "OPEN QUESTION 2                         18507\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(all_data_kojk_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                      0\n",
      "BIDANG                                  0\n",
      "SATKER (AKRONIM)                        0\n",
      "JENIS SURVEI                            0\n",
      "TIPE QUESTION                           0\n",
      "INSTITUSI / PERSEORANGAN/ASAL SATKER    0\n",
      "RESPOND                                 0\n",
      "LINK SURVEYMONKEY                       0\n",
      "TOKEN                                   0\n",
      "NAMA PIC/RESPONDEN                      0\n",
      "JABATAN/PROFESI/LVEL DI OJK             0\n",
      "KONTAK                                  0\n",
      "FUNGSI YANG DINILAI                     0\n",
      "DIRECT / INDIRECT                       0\n",
      "JENIS STAKEHOLDERS                      0\n",
      "RELASI RESPONDEN DENGAN SATKER          0\n",
      "POWER                                   0\n",
      "INTEREST                                0\n",
      "KATEGORI                                0\n",
      "Dataset                                 0\n",
      "RESOURCE PERCEPTION                     0\n",
      "PERFORMANCE DELIVERY                    0\n",
      "OPEN QUESTION 1                         0\n",
      "OPEN QUESTION 2                         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp_oh\\AppData\\Local\\Temp\\ipykernel_13512\\3413789475.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data_kojk_df.fillna(\"-\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "all_data_kojk_df.fillna(\"-\", inplace=True)\n",
    "\n",
    "print(all_data_kojk_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.141400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.284447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TOKEN\n",
       "count  20587.000000\n",
       "mean      18.141400\n",
       "std       11.284447\n",
       "min        1.000000\n",
       "25%        8.000000\n",
       "50%       20.000000\n",
       "75%       33.000000\n",
       "max       34.000000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_kojk_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+|\\@\\w+|\\#|\\d+|[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    cleaned_text = ' '.join(words)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from textblob import  TextBlob\n",
    "# #VALIDASI\n",
    "\n",
    "# file_path = 'data/hasil/main_data_idi.csv'\n",
    "\n",
    "# # Load dataset\n",
    "# data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# data_copy = data.copy()\n",
    "\n",
    "# # Fungsi untuk melakukan labeling berdasarkan polaritas\n",
    "# def assign_label(text):\n",
    "#     # Membuat objek TextBlob dari teks\n",
    "#     blob = TextBlob(text)\n",
    "    \n",
    "#     # Menghitung polaritas\n",
    "#     polarity = blob.sentiment.polarity\n",
    "    \n",
    "#     # Menentukan label berdasarkan polaritas\n",
    "#     if polarity > 0.5:\n",
    "#         return \"Sangat Setuju\"\n",
    "#     elif polarity > 0:\n",
    "#         return \"Setuju\"\n",
    "#     elif polarity == 0:\n",
    "#         return \"Cukup Setuju\"\n",
    "#     elif polarity < -0.5:\n",
    "#         return \"Sangat Tidak Setuju\"\n",
    "#     else:\n",
    "#         return \"Kurang Setuju\"\n",
    "\n",
    "\n",
    "# # Membaca file JSON yang berisi mapping\n",
    "# with open('mapping.json', 'r') as file:\n",
    "#     text_mapping = json.load(file)\n",
    "\n",
    "\n",
    "# # # Fungsi untuk menentukan label berdasarkan kata-kata dalam 'Combined_Text'\n",
    "# def map_combined_text_to_label(text):\n",
    "#     # Iterasi untuk mencari kata kunci dalam text\n",
    "#     for keyword, label in text_mapping.items():\n",
    "#         if keyword in text.lower():  # Mengabaikan kapitalisasi\n",
    "#             return label\n",
    "#     return 'setuju'  # Jika tidak ada kata kunci yang ditemukan\n",
    "\n",
    "# # Terapkan fungsi ke kolom 'Combined_Text' untuk membuat kolom 'Label'\n",
    "# data_copy['New_Label'] = data_copy['Combined_Text'].apply(assign_label)\n",
    "\n",
    "# # Tampilkan dataset yang sudah dimodifikasi\n",
    "# data_copy['Label'] = data_copy['New_Label'].combine_first(data_copy['Label'])\n",
    "\n",
    "# # Simpan dataset yang sudah dimodifikasi\n",
    "# # data_copy.to_csv('data/hasil/validated_dataset_new.csv', index=False, sep=';')\n",
    "\n",
    "# Menampilkan statistik label setelah perubahan\n",
    "# label_counts = data_copy['Label'].value_counts()\n",
    "# label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "# label_summary.columns = ['Label', 'Count']\n",
    "\n",
    "# label_map = {\n",
    "#     1: \"sangat tidak setuju\",\n",
    "#     2: \"tidak setuju\",\n",
    "#     3: \"kurang setuju\",\n",
    "#     4: \"cukup setuju\",\n",
    "#     5: \"setuju\",\n",
    "#     6: \"sangat setuju\"\n",
    "# }\n",
    "\n",
    "# reverse_label_map = {v: k for k, v in label_map.items()}  \n",
    "\n",
    "# data_copy['Label_Index'] = data_copy['Label'].map(reverse_label_map)\n",
    "\n",
    "# def calculate_weight(index):\n",
    "#     if index == 1:\n",
    "#         return 1\n",
    "#     elif 1.1 <= index <= 2.9:\n",
    "#         return 2.95\n",
    "#     elif 3 <= index <= 3.9:\n",
    "#         return 5.9\n",
    "#     elif 4 <= index <= 6:\n",
    "#         return 6\n",
    "#     else:\n",
    "#         return None  \n",
    "\n",
    "# data_copy['NILAI_SENTIMEN'] = data_copy['Label_Index'].apply(calculate_weight)\n",
    "\n",
    "# # print(data_copy)\n",
    "\n",
    "\n",
    "# print(data_copy[['Label','NILAI_SENTIMEN']])\n",
    "# data_copy.to_csv('data/hasil/main_data_idi.csv', index=False, sep=';')\n",
    "\n",
    "# label_counts = data_copy['Label'].value_counts()\n",
    "# label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "# label_summary.columns = ['Label', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Ganti model_name dengan model IndoBERT\n",
    "# model_name = \"indobenchmark/indobert-base-p1\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     model_name,\n",
    "#     num_labels=6  # Sesuaikan jumlah label\n",
    "# )\n",
    "\n",
    "# label_map = {\n",
    "#     0: \"sangat tidak setuju\",\n",
    "#     1: \"tidak setuju\",\n",
    "#     2: \"kurang setuju\",\n",
    "#     3: \"cukup setuju\",\n",
    "#     4: \"setuju\",\n",
    "#     5: \"sangat setuju\"\n",
    "# }\n",
    "\n",
    "# # Fungsi untuk memproses teks\n",
    "# def preprocess_text(text):\n",
    "#     return text.strip().lower() if isinstance(text, str) else \"\"  # Periksa apakah teks valid\n",
    "\n",
    "# # Fungsi untuk prediksi sentimen\n",
    "# def predict_sentiment(texts):\n",
    "#     model.eval()\n",
    "#     results = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for text in tqdm(texts):\n",
    "#             text = preprocess_text(text)\n",
    "            \n",
    "#             if not text:  # Lewati teks kosong\n",
    "#                 results.append({\n",
    "#                     'text': text,\n",
    "#                     'sentiment': \"unknown\",\n",
    "#                     'confidence': 0.0\n",
    "#                 })\n",
    "#                 continue\n",
    "            \n",
    "#             # Tokenisasi teks\n",
    "#             encoded = tokenizer(\n",
    "#                 text,\n",
    "#                 truncation=True,\n",
    "#                 padding=True,\n",
    "#                 max_length=512,\n",
    "#                 return_tensors=\"pt\"\n",
    "#             )\n",
    "            \n",
    "#             # Model memprediksi\n",
    "#             outputs = model(encoded[\"input_ids\"], attention_mask=encoded[\"attention_mask\"])\n",
    "#             predictions = F.softmax(outputs.logits, dim=1)\n",
    "#             predicted_label = torch.argmax(predictions, dim=1).item()\n",
    "            \n",
    "#             # Ambil confidence score\n",
    "#             confidence = predictions[0][predicted_label].item()\n",
    "            \n",
    "#             # Mapping hasil prediksi ke label\n",
    "#             sentiment = label_map.get(predicted_label, \"unknown\")\n",
    "            \n",
    "#             # Menambahkan hasil ke dalam list\n",
    "#             results.append({\n",
    "#                 'text': text,\n",
    "#                 'sentiment': sentiment,\n",
    "#                 'confidence': confidence\n",
    "#             })\n",
    "    \n",
    "#     return pd.DataFrame(results)\n",
    "\n",
    "# columns_to_process = ['OPEN QUESTION 1','OPEN QUESTION 2']\n",
    "\n",
    "# all_data_kojk_df['Text'] = all_data_kojk_df[columns_to_process].fillna(\"\").apply(lambda row: \" \".join(row), axis=1)\n",
    "\n",
    "# results = predict_sentiment(all_data_kojk_df['Text'].tolist())\n",
    "\n",
    "# all_data_kojk_df.loc[:, 'Label'] = results['sentiment']\n",
    "# all_data_kojk_df.loc[:, 'Confidence'] = results['confidence']\n",
    "\n",
    "# # Menampilkan hasil\n",
    "# print(\"\\nSample of labeled data:\")\n",
    "# print(all_data_kojk_df[['OPEN QUESTION 1','OPEN QUESTION 2','Label', 'Confidence']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\hp_oh\\AppData\\Local\\Temp\\ipykernel_13512\\4064108076.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data_kojk_df['Text'] = all_data_kojk_df[columns_to_process].fillna(\"\").apply(lambda row: \" \".join(row), axis=1)\n",
      "100%|██████████| 20587/20587 [16:09<00:00, 21.23it/s]\n",
      "C:\\Users\\hp_oh\\AppData\\Local\\Temp\\ipykernel_13512\\4064108076.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data_kojk_df.loc[:, 'Label'] = results['sentiment']\n",
      "C:\\Users\\hp_oh\\AppData\\Local\\Temp\\ipykernel_13512\\4064108076.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data_kojk_df.loc[:, 'Confidence'] = results['confidence']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of labeled data:\n",
      "  OPEN QUESTION 1                Label  Confidence\n",
      "0               -  sangat tidak setuju    0.250323\n",
      "1               -  sangat tidak setuju    0.250323\n",
      "2               -  sangat tidak setuju    0.250323\n",
      "3               -  sangat tidak setuju    0.250323\n",
      "4               -  sangat tidak setuju    0.250323\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ganti model_name dengan model IndoBERT\n",
    "model_name = \"indobenchmark/indobert-base-p1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=6  # Sesuaikan jumlah label\n",
    ")\n",
    "\n",
    "label_map = {\n",
    "    0: \"sangat tidak setuju\",\n",
    "    1: \"tidak setuju\",\n",
    "    2: \"kurang setuju\",\n",
    "    3: \"cukup setuju\",\n",
    "    4: \"setuju\",\n",
    "    5: \"sangat setuju\"\n",
    "}\n",
    "\n",
    "# Fungsi untuk memproses teks\n",
    "def preprocess_text(text):\n",
    "    return text.strip().lower() if isinstance(text, str) else \"\"  # Periksa apakah teks valid\n",
    "\n",
    "# Fungsi untuk prediksi sentimen\n",
    "def predict_sentiment(texts):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text in tqdm(texts):\n",
    "            text = preprocess_text(text)\n",
    "            \n",
    "            if not text:  # Lewati teks kosong\n",
    "                results.append({\n",
    "                    'text': text,\n",
    "                    'sentiment': \"unknown\",\n",
    "                    'confidence': 0.0\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Tokenisasi teks\n",
    "            encoded = tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # Model memprediksi\n",
    "            outputs = model(encoded[\"input_ids\"], attention_mask=encoded[\"attention_mask\"])\n",
    "            predictions = F.softmax(outputs.logits, dim=1)\n",
    "            predicted_label = torch.argmax(predictions, dim=1).item()\n",
    "            \n",
    "            # Ambil confidence score\n",
    "            confidence = predictions[0][predicted_label].item()\n",
    "            \n",
    "            # Mapping hasil prediksi ke label\n",
    "            sentiment = label_map.get(predicted_label, \"unknown\")\n",
    "            \n",
    "            # Menambahkan hasil ke dalam list\n",
    "            results.append({\n",
    "                'text': text,\n",
    "                'sentiment': sentiment,\n",
    "                'confidence': confidence\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "columns_to_process = ['OPEN QUESTION 1']\n",
    "\n",
    "all_data_kojk_df['Text'] = all_data_kojk_df[columns_to_process].fillna(\"\").apply(lambda row: \" \".join(row), axis=1)\n",
    "\n",
    "results = predict_sentiment(all_data_kojk_df['Text'].tolist())\n",
    "\n",
    "all_data_kojk_df.loc[:, 'Label'] = results['sentiment']\n",
    "all_data_kojk_df.loc[:, 'Confidence'] = results['confidence']\n",
    "\n",
    "# Menampilkan hasil\n",
    "print(\"\\nSample of labeled data:\")\n",
    "print(all_data_kojk_df[['OPEN QUESTION 1','Label', 'Confidence']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_kojk_df.to_csv('data/hasil/main_data_28_KOJK_OQ1.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           ID BIDANG SATKER (AKRONIM)  JENIS SURVEI  \\\n",
      "0      EKSTERNAL_KOJK_EMAIL_1     KS       KR1 - KOJT  NON INTERNAL   \n",
      "1      EKSTERNAL_KOJK_EMAIL_2     KS       KR1 - KOJT  NON INTERNAL   \n",
      "2      EKSTERNAL_KOJK_EMAIL_3     KS       KR1 - KOJT  NON INTERNAL   \n",
      "3      EKSTERNAL_KOJK_EMAIL_4     KS       KR1 - KOJT  NON INTERNAL   \n",
      "4      EKSTERNAL_KOJK_EMAIL_5     KS       KR1 - KOJT  NON INTERNAL   \n",
      "...                       ...    ...              ...           ...   \n",
      "20582  EKSTERNAL_KOJK_HP_5235     KS       KR3 - KOSG  NON INTERNAL   \n",
      "20583  EKSTERNAL_KOJK_HP_5236     KS       KR3 - KOSG  NON INTERNAL   \n",
      "20584  EKSTERNAL_KOJK_HP_5237     KS       KR3 - KOSG  NON INTERNAL   \n",
      "20585  EKSTERNAL_KOJK_HP_5238     KS       KR3 - KOSG  NON INTERNAL   \n",
      "20586  EKSTERNAL_KOJK_HP_5239     KS       KR3 - KOSG  NON INTERNAL   \n",
      "\n",
      "                                TIPE QUESTION  \\\n",
      "0                         PENGAWASAN LANGSUNG   \n",
      "1                         PENGAWASAN LANGSUNG   \n",
      "2                         PENGAWASAN LANGSUNG   \n",
      "3                         PENGAWASAN LANGSUNG   \n",
      "4                         PENGAWASAN LANGSUNG   \n",
      "...                                       ...   \n",
      "20582  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "20583  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "20584  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "20585  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "20586  EDUKASI DAN LITERASI KEUANGAN LANGSUNG   \n",
      "\n",
      "      INSTITUSI / PERSEORANGAN/ASAL SATKER       RESPOND LINK SURVEYMONKEY  \\\n",
      "0                              PT Bank DKI  BELUM DI ISI        LOGIC KOJK   \n",
      "1                      PT BPR Puspita Sari  BELUM DI ISI        LOGIC KOJK   \n",
      "2                 PT BPR Brilian Investama  BELUM DI ISI        LOGIC KOJK   \n",
      "3                 PT BPR Gita Makmur Utama  BELUM DI ISI        LOGIC KOJK   \n",
      "4                     PT BPR Darbeni Rizki  BELUM DI ISI        LOGIC KOJK   \n",
      "...                                    ...           ...               ...   \n",
      "20582              MARGARETA DIANA SAPUTRI  SUDAH DI ISI         KOJK HP 1   \n",
      "20583                    Irsyad Akmal Fata  BELUM DI ISI         KOJK HP 1   \n",
      "20584               Evrillyo Andea Gunawan  BELUM DI ISI         KOJK HP 1   \n",
      "20585      Muhammad Nashrul Muhtaril Fajar  BELUM DI ISI         KOJK HP 1   \n",
      "20586                   Saka Ardika Kusuma  BELUM DI ISI         KOJK HP 1   \n",
      "\n",
      "       TOKEN               NAMA PIC/RESPONDEN  ... INTEREST KATEGORI  \\\n",
      "0         23                      Ateng Rivai  ...     HIGH   PLAYER   \n",
      "1         23                            Yayuk  ...     HIGH   PLAYER   \n",
      "2         23                        Syukirman  ...     HIGH   PLAYER   \n",
      "3         23                    Lisa Andriani  ...     HIGH   PLAYER   \n",
      "4         20                    Agung Riyanto  ...     HIGH   PLAYER   \n",
      "...      ...                              ...  ...      ...      ...   \n",
      "20582      4          MARGARETA DIANA SAPUTRI  ...     HIGH   PLAYER   \n",
      "20583      4                Irsyad Akmal Fata  ...     HIGH   PLAYER   \n",
      "20584      4           Evrillyo Andea Gunawan  ...     HIGH   PLAYER   \n",
      "20585      4  Muhammad Nashrul Muhtaril Fajar  ...     HIGH   PLAYER   \n",
      "20586      4               Saka Ardika Kusuma  ...     HIGH   PLAYER   \n",
      "\n",
      "                   Dataset RESOURCE PERCEPTION PERFORMANCE DELIVERY  \\\n",
      "0      DATABASE KOJK EMAIL                   -                    -   \n",
      "1      DATABASE KOJK EMAIL                   -                    -   \n",
      "2      DATABASE KOJK EMAIL                   -                    -   \n",
      "3      DATABASE KOJK EMAIL                   -                    -   \n",
      "4      DATABASE KOJK EMAIL                   -                    -   \n",
      "...                    ...                 ...                  ...   \n",
      "20582  DATABASE KOJK NO HP                   6                    6   \n",
      "20583  DATABASE KOJK NO HP                   -                    -   \n",
      "20584  DATABASE KOJK NO HP                   -                    -   \n",
      "20585  DATABASE KOJK NO HP                   -                    -   \n",
      "20586  DATABASE KOJK NO HP                   -                    -   \n",
      "\n",
      "                                         OPEN QUESTION 1  \\\n",
      "0                                                      -   \n",
      "1                                                      -   \n",
      "2                                                      -   \n",
      "3                                                      -   \n",
      "4                                                      -   \n",
      "...                                                  ...   \n",
      "20582  Pelaksanaan kegiatan edukasi dan literasi keua...   \n",
      "20583                                                  -   \n",
      "20584                                                  -   \n",
      "20585                                                  -   \n",
      "20586                                                  -   \n",
      "\n",
      "                                         OPEN QUESTION 2  \\\n",
      "0                                                      -   \n",
      "1                                                      -   \n",
      "2                                                      -   \n",
      "3                                                      -   \n",
      "4                                                      -   \n",
      "...                                                  ...   \n",
      "20582  Saran untuk meningkatkan kegiatan edukasi dan ...   \n",
      "20583                                                  -   \n",
      "20584                                                  -   \n",
      "20585                                                  -   \n",
      "20586                                                  -   \n",
      "\n",
      "                                                    Text                Label  \\\n",
      "0                                                      -  sangat tidak setuju   \n",
      "1                                                      -  sangat tidak setuju   \n",
      "2                                                      -  sangat tidak setuju   \n",
      "3                                                      -  sangat tidak setuju   \n",
      "4                                                      -  sangat tidak setuju   \n",
      "...                                                  ...                  ...   \n",
      "20582  Pelaksanaan kegiatan edukasi dan literasi keua...  sangat tidak setuju   \n",
      "20583                                                  -  sangat tidak setuju   \n",
      "20584                                                  -  sangat tidak setuju   \n",
      "20585                                                  -  sangat tidak setuju   \n",
      "20586                                                  -  sangat tidak setuju   \n",
      "\n",
      "      Confidence  \n",
      "0       0.250323  \n",
      "1       0.250323  \n",
      "2       0.250323  \n",
      "3       0.250323  \n",
      "4       0.250323  \n",
      "...          ...  \n",
      "20582   0.241659  \n",
      "20583   0.250323  \n",
      "20584   0.250323  \n",
      "20585   0.250323  \n",
      "20586   0.250323  \n",
      "\n",
      "[20587 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_data_kojk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Menyimpan data ke file CSV\n",
    "# output_file = \"./data/hasil/all_data_idi_ss.csv\"\n",
    "# all_data_kojk_df.to_csv(output_file, index=False, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# print(f\"Data berhasil disimpan ke {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SAVE MODEL\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# # Ganti model_name dengan model IndoBERT\n",
    "# model_name = \"indobenchmark/indobert-base-p1\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     model_name,\n",
    "#     num_labels=6  # Sesuaikan jumlah label\n",
    "# )\n",
    "\n",
    "# # Menyimpan model dan tokenizer ke direktori\n",
    "# model_save_path = './saved_model'\n",
    "# tokenizer.save_pretrained(model_save_path)\n",
    "# model.save_pretrained(model_save_path)\n",
    "\n",
    "# print(f\"Model dan tokenizer berhasil disimpan di {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #LOAD MODEL\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# # Path ke model yang disimpan\n",
    "# model_save_path = './saved_model'\n",
    "\n",
    "# # Memuat model dan tokenizer dari path yang telah disimpan\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_save_path)\n",
    "\n",
    "# print(f\"Model dan tokenizer berhasil dimuat dari {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Label  Count\n",
      "0  sangat tidak setuju  19892\n",
      "1         tidak setuju    426\n",
      "2        sangat setuju    244\n",
      "3         cukup setuju     21\n",
      "4               setuju      4\n"
     ]
    }
   ],
   "source": [
    "label_counts = all_data_kojk_df['Label'].value_counts()\n",
    "\n",
    "label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "label_summary.columns = ['Label', 'Count']\n",
    "print(label_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs('data/hasil', exist_ok=True)\n",
    "# all_data_kojk_df.to_csv('data/hasil/labeled.csv', index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from textblob import TextBlob\n",
    "# #VALIDASI\n",
    "\n",
    "# file_path = 'data/hasil/main_data_REV.csv'\n",
    "\n",
    "# # Load dataset\n",
    "# data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# data_copy = data.copy()\n",
    "\n",
    "# # Fungsi untuk melakukan labeling berdasarkan polaritas\n",
    "# def assign_label(text):\n",
    "#     # Membuat objek TextBlob dari teks\n",
    "#     blob = TextBlob(text)\n",
    "    \n",
    "#     # Menghitung polaritas\n",
    "#     polarity = blob.sentiment.polarity\n",
    "    \n",
    "#     # Menentukan label berdasarkan polaritas\n",
    "#     if polarity > 0.5:\n",
    "#         return \"Sangat Setuju\"\n",
    "#     elif polarity > 0:\n",
    "#         return \"Setuju\"\n",
    "#     elif polarity == 0:\n",
    "#         return \"Cukup Setuju\"\n",
    "#     elif polarity < -0.5:\n",
    "#         return \"Sangat Tidak Setuju\"\n",
    "#     else:\n",
    "#         return \"Kurang Setuju\"\n",
    "\n",
    "\n",
    "# # # Membaca file JSON yang berisi mapping\n",
    "# with open('mapping.json', 'r') as file:\n",
    "#     text_mapping = json.load(file)\n",
    "\n",
    "\n",
    "# # # Fungsi untuk menentukan label berdasarkan kata-kata dalam 'Combined_Text'\n",
    "# def map_combined_text_to_label(text):\n",
    "#     # Iterasi untuk mencari kata kunci dalam text\n",
    "#     for keyword, label in text_mapping.items():\n",
    "#         if keyword in text.lower():  # Mengabaikan kapitalisasi\n",
    "#             return label\n",
    "#     return 'setuju'  # Jika tidak ada kata kunci yang ditemukan\n",
    "\n",
    "# # Terapkan fungsi ke kolom 'Combined_Text' untuk membuat kolom 'Label'\n",
    "# data_copy['New_Label'] = data_copy['Text'].apply(assign_label)\n",
    "\n",
    "# # Tampilkan dataset yang sudah dimodifikasi\n",
    "# data_copy['Label'] = data_copy['New_Label'].combine_first(data_copy['Label'])\n",
    "\n",
    "# # Simpan dataset yang sudah dimodifikasi\n",
    "# data_copy.to_csv('data/hasil/validated_dataset_new.csv', index=False, sep=';')\n",
    "\n",
    "# # Menampilkan statistik label setelah perubahan\n",
    "# label_counts = data_copy['Label'].value_counts()\n",
    "# label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "# label_summary.columns = ['Label', 'Count']\n",
    "\n",
    "# label_map = {\n",
    "#     1: \"sangat tidak setuju\",\n",
    "#     2: \"tidak setuju\",\n",
    "#     3: \"kurang setuju\",\n",
    "#     4: \"cukup setuju\",\n",
    "#     5: \"setuju\",\n",
    "#     6: \"sangat setuju\"\n",
    "# }\n",
    "\n",
    "# reverse_label_map = {v: k for k, v in label_map.items()}  \n",
    "\n",
    "# data_copy['Label_Index'] = data_copy['Label'].map(reverse_label_map)\n",
    "\n",
    "# def calculate_weight(index):\n",
    "#     if index == 1:\n",
    "#         return 1\n",
    "#     elif 1.1 <= index <= 2.9:\n",
    "#         return 2.95\n",
    "#     elif 3 <= index <= 3.9:\n",
    "#         return 5.9\n",
    "#     elif 4 <= index <= 6:\n",
    "#         return 6\n",
    "#     else:\n",
    "#         return None  \n",
    "\n",
    "# data_copy['NILAI_SENTIMEN'] = data_copy['Label_Index'].apply(calculate_weight)\n",
    "\n",
    "# # print(data_copy)\n",
    "\n",
    "\n",
    "# print(data_copy[['Label','NILAI_SENTIMEN']])\n",
    "# data_copy.to_csv('data/hasil/main_data_REVREV.csv', index=False, sep=';')\n",
    "\n",
    "# label_counts = data_copy['Label'].value_counts()\n",
    "# label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "# label_summary.columns = ['Label', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Label  NILAI_SENTIMEN\n",
      "0             setuju             6.0\n",
      "1             setuju             6.0\n",
      "2             setuju             6.0\n",
      "3             setuju             6.0\n",
      "4             setuju             6.0\n",
      "...              ...             ...\n",
      "20582  sangat setuju             6.0\n",
      "20583         setuju             6.0\n",
      "20584         setuju             6.0\n",
      "20585         setuju             6.0\n",
      "20586         setuju             6.0\n",
      "\n",
      "[20587 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# TODO: ini yang bener\n",
    "\n",
    "import json\n",
    "#VALIDASI\n",
    "\n",
    "file_path = 'data/hasil/main_data_28_KOJK_OQ1.csv'\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Membaca file JSON yang berisi mapping\n",
    "with open('mapping.json', 'r') as file:\n",
    "    text_mapping = json.load(file)\n",
    "    \n",
    "# data_copy['Text'] = data_copy['Text'].str.lower()\n",
    "\n",
    "# Fungsi untuk menentukan label berdasarkan kata-kata dalam 'Combined_Text'\n",
    "def map_combined_text_to_label(text):\n",
    "    # Iterasi untuk mencari kata kunci dalam text\n",
    "    for keyword, label in text_mapping.items():\n",
    "        if keyword in text.lower():  # Mengabaikan kapitalisasi\n",
    "            return label\n",
    "    return 'setuju'  # Jika tidak ada kata kunci yang ditemukan\n",
    "\n",
    "# Terapkan fungsi ke kolom 'Combined_Text' untuk membuat kolom 'Label'\n",
    "data_copy['New_Label'] = data_copy['Text'].apply(map_combined_text_to_label)\n",
    "\n",
    "# Tampilkan dataset yang sudah dimodifikasi\n",
    "data_copy['Label'] = data_copy['New_Label'].combine_first(data_copy['Label'])\n",
    "\n",
    "# Simpan dataset yang sudah dimodifikasi\n",
    "data_copy.to_csv('data/hasil/validated_dataset_new.csv', index=False, sep=';')\n",
    "\n",
    "# Menampilkan statistik label setelah perubahan\n",
    "label_counts = data_copy['Label'].value_counts()\n",
    "label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "label_summary.columns = ['Label', 'Count']\n",
    "\n",
    "label_map = {\n",
    "    1: \"sangat tidak setuju\",\n",
    "    2: \"tidak setuju\",\n",
    "    3: \"kurang setuju\",\n",
    "    4: \"cukup setuju\",\n",
    "    5: \"setuju\",\n",
    "    6: \"sangat setuju\"\n",
    "}\n",
    "\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}  \n",
    "\n",
    "data_copy['Label_Index'] = data_copy['Label'].map(reverse_label_map)\n",
    "\n",
    "def calculate_weight(index):\n",
    "    if index == 1:\n",
    "        return 1\n",
    "    elif 1.1 <= index <= 2.9:\n",
    "        return 2.95\n",
    "    elif 3 <= index <= 3.9:\n",
    "        return 5.9\n",
    "    elif 4 <= index <= 6:\n",
    "        return 6\n",
    "    else:\n",
    "        return None  \n",
    "\n",
    "data_copy['NILAI_SENTIMEN'] = data_copy['Label_Index'].apply(calculate_weight)\n",
    "\n",
    "# print(data_copy)\n",
    "\n",
    "\n",
    "print(data_copy[['Label','NILAI_SENTIMEN']])\n",
    "data_copy.to_csv('data/hasil/main_data_28_KOJK_OQ1_dashboard.csv', index=False, sep=';')\n",
    "\n",
    "label_counts = data_copy['Label'].value_counts()\n",
    "label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "label_summary.columns = ['Label', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Label  Count\n",
      "0         setuju  19763\n",
      "1  sangat setuju    518\n",
      "2   cukup setuju    246\n",
      "3  kurang setuju     51\n",
      "4   tidak setuju      9\n"
     ]
    }
   ],
   "source": [
    "label_counts = data_copy['Label'].value_counts()\n",
    "\n",
    "label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "label_summary.columns = ['Label', 'Count']\n",
    "print(label_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Read both datasets (with semicolon delimiter)\n",
    "# df_oq1 = pd.read_csv('data/hasil/main_data_28_KOJK_OQ1_dashboard.csv', sep=';')\n",
    "# df_oq2 = pd.read_csv('data/hasil/main_data_28_KOJK_OQ2_dashboard.csv', sep=';')\n",
    "\n",
    "# # Define common columns to maintain order\n",
    "# common_columns = [\n",
    "#     'ID',\n",
    "#     'BIDANG',\n",
    "#     'SATKER (AKRONIM)',\n",
    "#     'JENIS SURVEI',\n",
    "#     'TIPE QUESTION',\n",
    "#     'INSTITUSI / PERSEORANGAN/ASAL SATKER',\n",
    "#     'RESPOND',\n",
    "#     'LINK SURVEYMONKEY',\n",
    "#     'TOKEN',\n",
    "#     'NAMA PIC/RESPONDEN',\n",
    "#     'JABATAN/PROFESI/LVEL DI OJK',\n",
    "#     'KONTAK',\n",
    "#     'FUNGSI YANG DINILAI',\n",
    "#     'DIRECT / INDIRECT',\n",
    "#     'JENIS STAKEHOLDERS',\n",
    "#     'RELASI RESPONDEN DENGAN SATKER',\n",
    "#     'POWER',\n",
    "#     'INTEREST',\n",
    "#     'KATEGORI',\n",
    "#     'Dataset',\n",
    "#     'RESOURCE PERCEPTION',\n",
    "#     'PERFORMANCE DELIVERY',\n",
    "#     'OPEN QUESTION 1',\n",
    "#     'OPEN QUESTION 2',\n",
    "#     'Text',\n",
    "#     'Label',\n",
    "#     'Confidence',\n",
    "#     'New_Label'\n",
    "# ]\n",
    "\n",
    "# # Create new dataset\n",
    "# result_df = pd.DataFrame()\n",
    "\n",
    "# # Get unique IDs from both datasets\n",
    "# all_ids = pd.concat([df_oq1['ID'], df_oq2['ID']]).unique()\n",
    "# result_df['ID'] = all_ids\n",
    "\n",
    "# # Merge AF1 and AF2 from OQ1\n",
    "# result_df = result_df.merge(\n",
    "#     df_oq1[common_columns + ['NILAI_SENTIMEN', 'Label_Index']],\n",
    "#     on='ID',\n",
    "#     how='left'\n",
    "# ).rename(columns={\n",
    "#     'NILAI_SENTIMEN': 'AF1',\n",
    "#     'Label_Index': 'AF2'\n",
    "# })\n",
    "\n",
    "# # Merge AF3 and AF4 from OQ2\n",
    "# result_df = result_df.merge(\n",
    "#     df_oq2[['ID', 'NILAI_SENTIMEN', 'Label_Index']],\n",
    "#     on='ID',\n",
    "#     how='left'\n",
    "# ).rename(columns={\n",
    "#     'NILAI_SENTIMEN': 'AF3',\n",
    "#     'Label_Index': 'AF4'\n",
    "# })\n",
    "\n",
    "# # Calculate average\n",
    "# result_df['AF_AVERAGE'] = result_df[['AF1', 'AF2', 'AF3', 'AF4']].mean(axis=1)\n",
    "\n",
    "# # Reorder columns to put AF scores and average at the end\n",
    "# final_columns = common_columns + ['AF1', 'AF2', 'AF3', 'AF4', 'AF_AVERAGE']\n",
    "# result_df = result_df[final_columns]\n",
    "\n",
    "# # Save to new CSV file\n",
    "# result_df.to_csv('data/hasil/hasil_gabungan.csv', index=False, sep=';')\n",
    "\n",
    "# # Display results\n",
    "# print(\"Dataset hasil penggabungan:\")\n",
    "# print(result_df)\n",
    "\n",
    "# # Display information about the merged dataset\n",
    "# print(\"\\nInformasi dataset:\")\n",
    "# print(f\"Jumlah baris: {len(result_df)}\")\n",
    "# print(\"\\nStatistik AF_AVERAGE:\")\n",
    "# print(result_df['AF_AVERAGE'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
