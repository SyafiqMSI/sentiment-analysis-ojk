{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "os.makedirs(r'C:\\\\nltk_data', exist_ok=True)\n",
    "nltk.data.path.append(r'C:\\\\nltk_data')  \n",
    "nltk.download('punkt_tab', download_dir=r'C:\\\\nltk_data')\n",
    "nltk.download('stopwords', download_dir=r'C:\\\\nltk_data')\n",
    "nltk.download('wordnet', download_dir=r'C:\\\\nltk_data')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Dataset                      ID BIDANG SATKER (AKRONIM)  \\\n",
      "0           Database Internal    DATABASE INTERNAL_23     MS             DPSI   \n",
      "1           Database Internal    DATABASE INTERNAL_24     MS             DPSI   \n",
      "2           Database Internal    DATABASE INTERNAL_26     MS             DPSI   \n",
      "3           Database Internal    DATABASE INTERNAL_28     MS             DPSI   \n",
      "4           Database Internal    DATABASE INTERNAL_30     MS             DPSI   \n",
      "...                       ...                     ...    ...              ...   \n",
      "2916  DATABASE LOGIC INTERNAL  DATABASE INTERNAL_9528     MS             DPSU   \n",
      "2917  DATABASE LOGIC INTERNAL  DATABASE INTERNAL_9537     MS             DPSU   \n",
      "2918  DATABASE LOGIC INTERNAL  DATABASE INTERNAL_9540     MS             DPSU   \n",
      "2919  DATABASE LOGIC INTERNAL  DATABASE INTERNAL_9637    ARK             DPAI   \n",
      "2920  DATABASE LOGIC INTERNAL  DATABASE INTERNAL_9647    ARK             DPAI   \n",
      "\n",
      "     JENIS SURVEI  TIPE QUESTION INSTITUSI / PERSEORANGAN/ASAL SATKER  \\\n",
      "0        INTERNAL    DIRECT DPSI                                 DPAI   \n",
      "1        INTERNAL    DIRECT DPSI                                 DPAI   \n",
      "2        INTERNAL    DIRECT DPSI                                 DPAI   \n",
      "3        INTERNAL    DIRECT DPSI                                 DPAI   \n",
      "4        INTERNAL    DIRECT DPSI                                 DPAI   \n",
      "...           ...            ...                                  ...   \n",
      "2916     INTERNAL  INDIRECT DPSU                                 DRPK   \n",
      "2917     INTERNAL  INDIRECT DPSU                                 KODS   \n",
      "2918     INTERNAL    DIRECT DPSU                                 DINP   \n",
      "2919     INTERNAL    DIRECT DPAI                                  ADK   \n",
      "2920     INTERNAL    DIRECT DPAI                                 DKKL   \n",
      "\n",
      "           RESPOND                                  LINK SURVEYMONKEY  \\\n",
      "0     SUDAH DI ISI    Internal 2 (Direct DOSB & Direct DPSI, 129_173)   \n",
      "1     SUDAH DI ISI  Internal 1 (Direct DPSI & Indirect DOSB, 253_2...   \n",
      "2     SUDAH DI ISI  Internal 1 (Direct DPSI & Indirect DOSB, 253_2...   \n",
      "3     SUDAH DI ISI  Internal 1 (Direct DPSI & Indirect DOSB, 253_2...   \n",
      "4     SUDAH DI ISI  Internal 1 (Direct DPSI & Indirect DOSB, 253_2...   \n",
      "...            ...                                                ...   \n",
      "2916  SUDAH DI ISI                                              LOGIC   \n",
      "2917  SUDAH DI ISI                                              LOGIC   \n",
      "2918  SUDAH DI ISI                                              LOGIC   \n",
      "2919  SUDAH DI ISI                                              LOGIC   \n",
      "2920  SUDAH DI ISI                                              LOGIC   \n",
      "\n",
      "                  WEBLINK SURVEYMONKEY  ... INTEREST  KATEGORI  \\\n",
      "0     http://uns.id/SurveyInternalOJK2  ...     HIGH    PLAYER   \n",
      "1     http://uns.id/SurveyInternalOJK1  ...     HIGH    PLAYER   \n",
      "2     http://uns.id/SurveyInternalOJK1  ...     HIGH    PLAYER   \n",
      "3     http://uns.id/SurveyInternalOJK1  ...     HIGH    PLAYER   \n",
      "4     http://uns.id/SurveyInternalOJK1  ...     HIGH    PLAYER   \n",
      "...                                ...  ...      ...       ...   \n",
      "2916                                 0  ...     high  Subjects   \n",
      "2917                                 0  ...     high  Subjects   \n",
      "2918                                 0  ...     high    Player   \n",
      "2919                                 0  ...     High    Player   \n",
      "2920                                 0  ...     High    Player   \n",
      "\n",
      "     TANGGAL PENGISIAN  0 RESOURCE PERCEPTION PERFORMANCE DELIVERY OS PENTING  \\\n",
      "0           12/02/2024  0         5,333333333          5,285714286          6   \n",
      "1           12/09/2024  0         5,666666667                    6          6   \n",
      "2           12/09/2024  0                   5                    5          6   \n",
      "3           12/12/2024  0                   6          5,285714286          6   \n",
      "4           12/12/2024  0         5,666666667                    6          6   \n",
      "...                ... ..                 ...                  ...        ...   \n",
      "2916          1/0/1900  0                   0                    0        NaN   \n",
      "2917        12/04/2024  0                   0                    0          5   \n",
      "2918        12/05/2024  0                   5                    5          5   \n",
      "2919        12/09/2024  0                 NaN                  NaN        NaN   \n",
      "2920          1/0/1900  0                   5          4,833333333          4   \n",
      "\n",
      "     OS PUAS                                    OPEN QUESTION 1  \\\n",
      "0          5  Sdh sangat bagus hanya banyak terkendala krn k...   \n",
      "1          6                                        sangat baik   \n",
      "2          5                            sudah baik, pertahankan   \n",
      "3          6                     Sejauh ini baik dan responsif.   \n",
      "4          6  Pengelolaan sistem informasi oleh DPSI OJK tel...   \n",
      "...      ...                                                ...   \n",
      "2916     NaN                                                  0   \n",
      "2917       6               mempermudah monev sipo bagi pengawas   \n",
      "2918       6  Untuk menyediakan alat bantu (aplikasi) atau k...   \n",
      "2919     NaN                                                  0   \n",
      "2920       4                                                  -   \n",
      "\n",
      "                                        OPEN QUESTION 2  \n",
      "0     fungsi pengelolaan informasi harus imbang anta...  \n",
      "1                                                     -  \n",
      "2     sudah cukup baik pertahankan kinerja yang suda...  \n",
      "3     Agar terdapat no wa helpdesk per masing-masing...  \n",
      "4     agar dapat setiap pegawai di fasilitas dengan ...  \n",
      "...                                                 ...  \n",
      "2916                                                  0  \n",
      "2917                                                  0  \n",
      "2918                                                  0  \n",
      "2919                                                  0  \n",
      "2920                                                  -  \n",
      "\n",
      "[2921 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_database_result_csv(file_path):\n",
    "    try:\n",
    "        # Mencoba membaca dengan encoding default (utf-8) dan delimiter koma\n",
    "        df = pd.read_csv(file_path, sep=';', encoding='utf-8')\n",
    "    except UnicodeDecodeError as e1:\n",
    "        try:\n",
    "            # Jika gagal, mencoba dengan encoding latin1\n",
    "            df = pd.read_csv(file_path, sep=';', encoding='latin1')\n",
    "        except UnicodeDecodeError as e2:\n",
    "            try:\n",
    "                # Jika gagal, mencoba dengan encoding cp1252\n",
    "                df = pd.read_csv(file_path, sep=';', encoding='cp1252')\n",
    "            except Exception as e3:\n",
    "                print(f\"Gagal membaca file {file_path}: {e1} | {e2} | {e3}\")\n",
    "                return pd.DataFrame()  # Mengembalikan DataFrame kosong jika gagal\n",
    "    return df\n",
    "\n",
    "# Path ke file DATABASE_RESULT_OJK.csv\n",
    "file_path = 'data/main_data_17.csv'\n",
    "database_result_df = read_database_result_csv(file_path)\n",
    "\n",
    "print(database_result_df)\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# def read_database_result_excel(file_path):\n",
    "#     try:\n",
    "#         # Membaca file Excel\n",
    "#         df = pd.read_excel(file_path, engine='openpyxl')\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"File tidak ditemukan: {file_path}\")\n",
    "#         return pd.DataFrame()  # Mengembalikan DataFrame kosong jika file tidak ditemukan\n",
    "#     except Exception as e:\n",
    "#         print(f\"Gagal membaca file Excel {file_path}: {e}\")\n",
    "#         return pd.DataFrame()  # Mengembalikan DataFrame kosong jika gagal membaca\n",
    "#     return df\n",
    "\n",
    "# # Path ke file DATABASE_RESULT_OJK.xlsx\n",
    "# file_path = 'DATABASE BESAR OJK X FINTECH UNS.xlsx'\n",
    "# database_result_df = read_database_result_excel(file_path)\n",
    "\n",
    "# print(database_result_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #FILTERING SATKER\n",
    "\n",
    "# # Menentukan filter SATKER yang diinginkan\n",
    "# filter_option = input(\"Apakah Anda ingin memilih SATKER berdasarkan pilihan tertentu (y/n)? \")\n",
    "\n",
    "# if filter_option.lower() == 'y':\n",
    "#     # Jika pengguna memilih untuk memasukkan SATKER\n",
    "#     selected_satker = input(\"Masukkan SATKER yang ingin difilter (misal: 'DPEA'): \")\n",
    "    \n",
    "#     # Memfilter data berdasarkan SATKER yang dipilih\n",
    "#     filtered_df = database_result_df[database_result_df['SATKER (AKRONIM)'] == selected_satker]\n",
    "#     print(f\"Data difilter berdasarkan SATKER: {selected_satker}\")\n",
    "    \n",
    "# elif filter_option.lower() == 'n':\n",
    "#     # Jika pengguna memilih untuk memfilter berdasarkan beberapa SATKER tertentu\n",
    "#     selected_satker_list = ['DPEA', 'DOSB', 'DPSI']  # Contoh daftar SATKER yang bisa dipilih\n",
    "#     filtered_df = database_result_df[database_result_df['SATKER (AKRONIM)'].isin(selected_satker_list)]\n",
    "#     print(f\"Data difilter berdasarkan beberapa SATKER: {', '.join(selected_satker_list)}\")\n",
    "    \n",
    "# else:\n",
    "#     # Jika input selain 'y' atau 'n', tampilkan pesan\n",
    "#     print(\"Pilihan tidak valid. Menggunakan data tanpa filter.\")\n",
    "#     filtered_df = database_result_df\n",
    "\n",
    "# # Menampilkan data yang sudah difilter\n",
    "# print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(database_result_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop = database_result_df.drop(index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order = [\n",
    "    'ID','BIDANG','SATKER (AKRONIM)','JENIS SURVEI','TIPE QUESTION','INSTITUSI / PERSEORANGAN/ASAL SATKER','RESPOND','LINK SURVEYMONKEY','TOKEN','NAMA PIC/RESPONDEN','JABATAN/PROFESI/LVEL DI OJK','KONTAK','FUNGSI YANG DINILAI','DIRECT / INDIRECT','JENIS STAKEHOLDERS','RELASI RESPONDEN DENGAN SATKER','POWER','INTEREST','KATEGORI','Dataset','RESOURCE PERCEPTION','PERFORMANCE DELIVERY','OPEN QUESTION 1','OPEN QUESTION 2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_idi_df = database_result_df[columns_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          ID BIDANG SATKER (AKRONIM) JENIS SURVEI  \\\n",
      "0       DATABASE INTERNAL_23     MS             DPSI     INTERNAL   \n",
      "1       DATABASE INTERNAL_24     MS             DPSI     INTERNAL   \n",
      "2       DATABASE INTERNAL_26     MS             DPSI     INTERNAL   \n",
      "3       DATABASE INTERNAL_28     MS             DPSI     INTERNAL   \n",
      "4       DATABASE INTERNAL_30     MS             DPSI     INTERNAL   \n",
      "...                      ...    ...              ...          ...   \n",
      "2916  DATABASE INTERNAL_9528     MS             DPSU     INTERNAL   \n",
      "2917  DATABASE INTERNAL_9537     MS             DPSU     INTERNAL   \n",
      "2918  DATABASE INTERNAL_9540     MS             DPSU     INTERNAL   \n",
      "2919  DATABASE INTERNAL_9637    ARK             DPAI     INTERNAL   \n",
      "2920  DATABASE INTERNAL_9647    ARK             DPAI     INTERNAL   \n",
      "\n",
      "      TIPE QUESTION INSTITUSI / PERSEORANGAN/ASAL SATKER       RESPOND  \\\n",
      "0       DIRECT DPSI                                 DPAI  SUDAH DI ISI   \n",
      "1       DIRECT DPSI                                 DPAI  SUDAH DI ISI   \n",
      "2       DIRECT DPSI                                 DPAI  SUDAH DI ISI   \n",
      "3       DIRECT DPSI                                 DPAI  SUDAH DI ISI   \n",
      "4       DIRECT DPSI                                 DPAI  SUDAH DI ISI   \n",
      "...             ...                                  ...           ...   \n",
      "2916  INDIRECT DPSU                                 DRPK  SUDAH DI ISI   \n",
      "2917  INDIRECT DPSU                                 KODS  SUDAH DI ISI   \n",
      "2918    DIRECT DPSU                                 DINP  SUDAH DI ISI   \n",
      "2919    DIRECT DPAI                                  ADK  SUDAH DI ISI   \n",
      "2920    DIRECT DPAI                                 DKKL  SUDAH DI ISI   \n",
      "\n",
      "                                      LINK SURVEYMONKEY       TOKEN  \\\n",
      "0       Internal 2 (Direct DOSB & Direct DPSI, 129_173)  Token 0128   \n",
      "1     Internal 1 (Direct DPSI & Indirect DOSB, 253_2...  Token 0252   \n",
      "2     Internal 1 (Direct DPSI & Indirect DOSB, 253_2...  Token 0252   \n",
      "3     Internal 1 (Direct DPSI & Indirect DOSB, 253_2...  Token 0252   \n",
      "4     Internal 1 (Direct DPSI & Indirect DOSB, 253_2...  Token 0252   \n",
      "...                                                 ...         ...   \n",
      "2916                                              LOGIC  Token 0086   \n",
      "2917                                              LOGIC  Token 0116   \n",
      "2918                                              LOGIC  Token 0035   \n",
      "2919                                              LOGIC  Token 0130   \n",
      "2920                                              LOGIC  Token 0074   \n",
      "\n",
      "                    NAMA PIC/RESPONDEN  ... JENIS STAKEHOLDERS  \\\n",
      "0          Albertus Widjono Pratijakso  ...        PEGAWAI OJK   \n",
      "1     Glendy Mario Constantine Walujan  ...        PEGAWAI OJK   \n",
      "2                      Tengku Faradina  ...        PEGAWAI OJK   \n",
      "3                     Sefrina Widyanti  ...        PEGAWAI OJK   \n",
      "4                 Aditya Arief Nugraha  ...        PEGAWAI OJK   \n",
      "...                                ...  ...                ...   \n",
      "2916                  Retno Woelandari  ...        PEGAWAI OJK   \n",
      "2917           Kristrianti Puji Rahayu  ...        PEGAWAI OJK   \n",
      "2918               Rachman Arief Bakry  ...        PEGAWAI OJK   \n",
      "2919         Sophia Issabella Watimena  ...        PEGAWAI OJK   \n",
      "2920                      Aman Santosa  ...        PEGAWAI OJK   \n",
      "\n",
      "                RELASI RESPONDEN DENGAN SATKER POWER INTEREST  KATEGORI  \\\n",
      "0     PENERIMA HELPDESK & LAYANAN DPSI LAINNYA  HIGH     HIGH    PLAYER   \n",
      "1     PENERIMA HELPDESK & LAYANAN DPSI LAINNYA  HIGH     HIGH    PLAYER   \n",
      "2     PENERIMA HELPDESK & LAYANAN DPSI LAINNYA  HIGH     HIGH    PLAYER   \n",
      "3     PENERIMA HELPDESK & LAYANAN DPSI LAINNYA  HIGH     HIGH    PLAYER   \n",
      "4     PENERIMA HELPDESK & LAYANAN DPSI LAINNYA  HIGH     HIGH    PLAYER   \n",
      "...                                        ...   ...      ...       ...   \n",
      "2916       Kepala Satker MIA/PPD/Dewan Redaksi   low     high  Subjects   \n",
      "2917       Kepala Satker MIA/PPD/Dewan Redaksi   low     high  Subjects   \n",
      "2918                                       PPD  high     high    Player   \n",
      "2919                      DEWAN KOMISIONER OJK  High     High    Player   \n",
      "2920  Kebijakan Kelogistikan, IKU dan Anggaran  High     High    Player   \n",
      "\n",
      "                      Dataset RESOURCE PERCEPTION PERFORMANCE DELIVERY  \\\n",
      "0           Database Internal         5,333333333          5,285714286   \n",
      "1           Database Internal         5,666666667                    6   \n",
      "2           Database Internal                   5                    5   \n",
      "3           Database Internal                   6          5,285714286   \n",
      "4           Database Internal         5,666666667                    6   \n",
      "...                       ...                 ...                  ...   \n",
      "2916  DATABASE LOGIC INTERNAL                   0                    0   \n",
      "2917  DATABASE LOGIC INTERNAL                   0                    0   \n",
      "2918  DATABASE LOGIC INTERNAL                   5                    5   \n",
      "2919  DATABASE LOGIC INTERNAL                 NaN                  NaN   \n",
      "2920  DATABASE LOGIC INTERNAL                   5          4,833333333   \n",
      "\n",
      "                                        OPEN QUESTION 1  \\\n",
      "0     Sdh sangat bagus hanya banyak terkendala krn k...   \n",
      "1                                           sangat baik   \n",
      "2                               sudah baik, pertahankan   \n",
      "3                        Sejauh ini baik dan responsif.   \n",
      "4     Pengelolaan sistem informasi oleh DPSI OJK tel...   \n",
      "...                                                 ...   \n",
      "2916                                                  0   \n",
      "2917               mempermudah monev sipo bagi pengawas   \n",
      "2918  Untuk menyediakan alat bantu (aplikasi) atau k...   \n",
      "2919                                                  0   \n",
      "2920                                                  -   \n",
      "\n",
      "                                        OPEN QUESTION 2  \n",
      "0     fungsi pengelolaan informasi harus imbang anta...  \n",
      "1                                                     -  \n",
      "2     sudah cukup baik pertahankan kinerja yang suda...  \n",
      "3     Agar terdapat no wa helpdesk per masing-masing...  \n",
      "4     agar dapat setiap pegawai di fasilitas dengan ...  \n",
      "...                                                 ...  \n",
      "2916                                                  0  \n",
      "2917                                                  0  \n",
      "2918                                                  0  \n",
      "2919                                                  0  \n",
      "2920                                                  -  \n",
      "\n",
      "[2921 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_data_idi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                       0\n",
      "BIDANG                                   0\n",
      "SATKER (AKRONIM)                         0\n",
      "JENIS SURVEI                             0\n",
      "TIPE QUESTION                            0\n",
      "INSTITUSI / PERSEORANGAN/ASAL SATKER     0\n",
      "RESPOND                                  0\n",
      "LINK SURVEYMONKEY                        0\n",
      "TOKEN                                    0\n",
      "NAMA PIC/RESPONDEN                       0\n",
      "JABATAN/PROFESI/LVEL DI OJK              0\n",
      "KONTAK                                   0\n",
      "FUNGSI YANG DINILAI                      0\n",
      "DIRECT / INDIRECT                        0\n",
      "JENIS STAKEHOLDERS                       0\n",
      "RELASI RESPONDEN DENGAN SATKER           0\n",
      "POWER                                    0\n",
      "INTEREST                                 0\n",
      "KATEGORI                                 0\n",
      "Dataset                                  0\n",
      "RESOURCE PERCEPTION                     60\n",
      "PERFORMANCE DELIVERY                    60\n",
      "OPEN QUESTION 1                          6\n",
      "OPEN QUESTION 2                          8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(all_data_idi_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                      0\n",
      "BIDANG                                  0\n",
      "SATKER (AKRONIM)                        0\n",
      "JENIS SURVEI                            0\n",
      "TIPE QUESTION                           0\n",
      "INSTITUSI / PERSEORANGAN/ASAL SATKER    0\n",
      "RESPOND                                 0\n",
      "LINK SURVEYMONKEY                       0\n",
      "TOKEN                                   0\n",
      "NAMA PIC/RESPONDEN                      0\n",
      "JABATAN/PROFESI/LVEL DI OJK             0\n",
      "KONTAK                                  0\n",
      "FUNGSI YANG DINILAI                     0\n",
      "DIRECT / INDIRECT                       0\n",
      "JENIS STAKEHOLDERS                      0\n",
      "RELASI RESPONDEN DENGAN SATKER          0\n",
      "POWER                                   0\n",
      "INTEREST                                0\n",
      "KATEGORI                                0\n",
      "Dataset                                 0\n",
      "RESOURCE PERCEPTION                     0\n",
      "PERFORMANCE DELIVERY                    0\n",
      "OPEN QUESTION 1                         0\n",
      "OPEN QUESTION 2                         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_38508\\4226600997.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data_idi_df.fillna(\"-\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "all_data_idi_df.fillna(\"-\", inplace=True)\n",
    "\n",
    "print(all_data_idi_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_idi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+|\\@\\w+|\\#|\\d+|[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    cleaned_text = ' '.join(words)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from textblob import  TextBlob\n",
    "# #VALIDASI\n",
    "\n",
    "# file_path = 'data/hasil/main_data_idi.csv'\n",
    "\n",
    "# # Load dataset\n",
    "# data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# data_copy = data.copy()\n",
    "\n",
    "# # Fungsi untuk melakukan labeling berdasarkan polaritas\n",
    "# def assign_label(text):\n",
    "#     # Membuat objek TextBlob dari teks\n",
    "#     blob = TextBlob(text)\n",
    "    \n",
    "#     # Menghitung polaritas\n",
    "#     polarity = blob.sentiment.polarity\n",
    "    \n",
    "#     # Menentukan label berdasarkan polaritas\n",
    "#     if polarity > 0.5:\n",
    "#         return \"Sangat Setuju\"\n",
    "#     elif polarity > 0:\n",
    "#         return \"Setuju\"\n",
    "#     elif polarity == 0:\n",
    "#         return \"Cukup Setuju\"\n",
    "#     elif polarity < -0.5:\n",
    "#         return \"Sangat Tidak Setuju\"\n",
    "#     else:\n",
    "#         return \"Kurang Setuju\"\n",
    "\n",
    "\n",
    "# # Membaca file JSON yang berisi mapping\n",
    "# with open('mapping.json', 'r') as file:\n",
    "#     text_mapping = json.load(file)\n",
    "\n",
    "\n",
    "# # # Fungsi untuk menentukan label berdasarkan kata-kata dalam 'Combined_Text'\n",
    "# def map_combined_text_to_label(text):\n",
    "#     # Iterasi untuk mencari kata kunci dalam text\n",
    "#     for keyword, label in text_mapping.items():\n",
    "#         if keyword in text.lower():  # Mengabaikan kapitalisasi\n",
    "#             return label\n",
    "#     return 'setuju'  # Jika tidak ada kata kunci yang ditemukan\n",
    "\n",
    "# # Terapkan fungsi ke kolom 'Combined_Text' untuk membuat kolom 'Label'\n",
    "# data_copy['New_Label'] = data_copy['Combined_Text'].apply(assign_label)\n",
    "\n",
    "# # Tampilkan dataset yang sudah dimodifikasi\n",
    "# data_copy['Label'] = data_copy['New_Label'].combine_first(data_copy['Label'])\n",
    "\n",
    "# # Simpan dataset yang sudah dimodifikasi\n",
    "# # data_copy.to_csv('data/hasil/validated_dataset_new.csv', index=False, sep=';')\n",
    "\n",
    "# Menampilkan statistik label setelah perubahan\n",
    "# label_counts = data_copy['Label'].value_counts()\n",
    "# label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "# label_summary.columns = ['Label', 'Count']\n",
    "\n",
    "# label_map = {\n",
    "#     1: \"sangat tidak setuju\",\n",
    "#     2: \"tidak setuju\",\n",
    "#     3: \"kurang setuju\",\n",
    "#     4: \"cukup setuju\",\n",
    "#     5: \"setuju\",\n",
    "#     6: \"sangat setuju\"\n",
    "# }\n",
    "\n",
    "# reverse_label_map = {v: k for k, v in label_map.items()}  \n",
    "\n",
    "# data_copy['Label_Index'] = data_copy['Label'].map(reverse_label_map)\n",
    "\n",
    "# def calculate_weight(index):\n",
    "#     if index == 1:\n",
    "#         return 1\n",
    "#     elif 1.1 <= index <= 2.9:\n",
    "#         return 2.95\n",
    "#     elif 3 <= index <= 3.9:\n",
    "#         return 5.9\n",
    "#     elif 4 <= index <= 6:\n",
    "#         return 6\n",
    "#     else:\n",
    "#         return None  \n",
    "\n",
    "# data_copy['NILAI_SENTIMEN'] = data_copy['Label_Index'].apply(calculate_weight)\n",
    "\n",
    "# # print(data_copy)\n",
    "\n",
    "\n",
    "# print(data_copy[['Label','NILAI_SENTIMEN']])\n",
    "# data_copy.to_csv('data/hasil/main_data_idi.csv', index=False, sep=';')\n",
    "\n",
    "# label_counts = data_copy['Label'].value_counts()\n",
    "# label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "# label_summary.columns = ['Label', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30824\\1506450411.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data_idi_df['Text'] = all_data_idi_df[columns_to_process].fillna(\"\").apply(lambda row: \" \".join(row), axis=1)\n",
      "100%|██████████| 2921/2921 [04:12<00:00, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of labeled data:\n",
      "                                     OPEN QUESTION 1  \\\n",
      "0  Sdh sangat bagus hanya banyak terkendala krn k...   \n",
      "1                                        sangat baik   \n",
      "2                            sudah baik, pertahankan   \n",
      "3                     Sejauh ini baik dan responsif.   \n",
      "4  Pengelolaan sistem informasi oleh DPSI OJK tel...   \n",
      "\n",
      "                                     OPEN QUESTION 2         Label  Confidence  \n",
      "0  fungsi pengelolaan informasi harus imbang anta...  tidak setuju    0.280958  \n",
      "1                                                  -  tidak setuju    0.194074  \n",
      "2  sudah cukup baik pertahankan kinerja yang suda...  tidak setuju    0.254202  \n",
      "3  Agar terdapat no wa helpdesk per masing-masing...  tidak setuju    0.283238  \n",
      "4  agar dapat setiap pegawai di fasilitas dengan ...  tidak setuju    0.235132  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30824\\1506450411.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data_idi_df.loc[:, 'Label'] = results['sentiment']\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30824\\1506450411.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data_idi_df.loc[:, 'Confidence'] = results['confidence']\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Ganti model_name dengan model IndoBERT\n",
    "# model_name = \"indobenchmark/indobert-base-p1\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     model_name,\n",
    "#     num_labels=6  # Sesuaikan jumlah label\n",
    "# )\n",
    "\n",
    "# label_map = {\n",
    "#     0: \"sangat tidak setuju\",\n",
    "#     1: \"tidak setuju\",\n",
    "#     2: \"kurang setuju\",\n",
    "#     3: \"cukup setuju\",\n",
    "#     4: \"setuju\",\n",
    "#     5: \"sangat setuju\"\n",
    "# }\n",
    "\n",
    "# # Fungsi untuk memproses teks\n",
    "# def preprocess_text(text):\n",
    "#     return text.strip().lower() if isinstance(text, str) else \"\"  # Periksa apakah teks valid\n",
    "\n",
    "# # Fungsi untuk prediksi sentimen\n",
    "# def predict_sentiment(texts):\n",
    "#     model.eval()\n",
    "#     results = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for text in tqdm(texts):\n",
    "#             text = preprocess_text(text)\n",
    "            \n",
    "#             if not text:  # Lewati teks kosong\n",
    "#                 results.append({\n",
    "#                     'text': text,\n",
    "#                     'sentiment': \"unknown\",\n",
    "#                     'confidence': 0.0\n",
    "#                 })\n",
    "#                 continue\n",
    "            \n",
    "#             # Tokenisasi teks\n",
    "#             encoded = tokenizer(\n",
    "#                 text,\n",
    "#                 truncation=True,\n",
    "#                 padding=True,\n",
    "#                 max_length=512,\n",
    "#                 return_tensors=\"pt\"\n",
    "#             )\n",
    "            \n",
    "#             # Model memprediksi\n",
    "#             outputs = model(encoded[\"input_ids\"], attention_mask=encoded[\"attention_mask\"])\n",
    "#             predictions = F.softmax(outputs.logits, dim=1)\n",
    "#             predicted_label = torch.argmax(predictions, dim=1).item()\n",
    "            \n",
    "#             # Ambil confidence score\n",
    "#             confidence = predictions[0][predicted_label].item()\n",
    "            \n",
    "#             # Mapping hasil prediksi ke label\n",
    "#             sentiment = label_map.get(predicted_label, \"unknown\")\n",
    "            \n",
    "#             # Menambahkan hasil ke dalam list\n",
    "#             results.append({\n",
    "#                 'text': text,\n",
    "#                 'sentiment': sentiment,\n",
    "#                 'confidence': confidence\n",
    "#             })\n",
    "    \n",
    "#     return pd.DataFrame(results)\n",
    "\n",
    "# columns_to_process = ['OPEN QUESTION 1','OPEN QUESTION 2']\n",
    "\n",
    "# all_data_idi_df['Text'] = all_data_idi_df[columns_to_process].fillna(\"\").apply(lambda row: \" \".join(row), axis=1)\n",
    "\n",
    "# results = predict_sentiment(all_data_idi_df['Text'].tolist())\n",
    "\n",
    "# all_data_idi_df.loc[:, 'Label'] = results['sentiment']\n",
    "# all_data_idi_df.loc[:, 'Confidence'] = results['confidence']\n",
    "\n",
    "# # Menampilkan hasil\n",
    "# print(\"\\nSample of labeled data:\")\n",
    "# print(all_data_idi_df[['OPEN QUESTION 1','OPEN QUESTION 2','Label', 'Confidence']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_38508\\3337752218.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data_idi_df['Text'] = all_data_idi_df[columns_to_process].fillna(\"\").apply(lambda row: \" \".join(row), axis=1)\n",
      "100%|██████████| 2921/2921 [03:49<00:00, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of labeled data:\n",
      "                                     OPEN QUESTION 1          Label  \\\n",
      "0  Sdh sangat bagus hanya banyak terkendala krn k...         setuju   \n",
      "1                                        sangat baik         setuju   \n",
      "2                            sudah baik, pertahankan   cukup setuju   \n",
      "3                     Sejauh ini baik dan responsif.   cukup setuju   \n",
      "4  Pengelolaan sistem informasi oleh DPSI OJK tel...  kurang setuju   \n",
      "\n",
      "   Confidence  \n",
      "0    0.222106  \n",
      "1    0.199094  \n",
      "2    0.208029  \n",
      "3    0.213246  \n",
      "4    0.229381  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_38508\\3337752218.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data_idi_df.loc[:, 'Label'] = results['sentiment']\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_38508\\3337752218.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data_idi_df.loc[:, 'Confidence'] = results['confidence']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ganti model_name dengan model IndoBERT\n",
    "model_name = \"indobenchmark/indobert-base-p1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=6  # Sesuaikan jumlah label\n",
    ")\n",
    "\n",
    "label_map = {\n",
    "    0: \"sangat tidak setuju\",\n",
    "    1: \"tidak setuju\",\n",
    "    2: \"kurang setuju\",\n",
    "    3: \"cukup setuju\",\n",
    "    4: \"setuju\",\n",
    "    5: \"sangat setuju\"\n",
    "}\n",
    "\n",
    "# Fungsi untuk memproses teks\n",
    "def preprocess_text(text):\n",
    "    return text.strip().lower() if isinstance(text, str) else \"\"  # Periksa apakah teks valid\n",
    "\n",
    "# Fungsi untuk prediksi sentimen\n",
    "def predict_sentiment(texts):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text in tqdm(texts):\n",
    "            text = preprocess_text(text)\n",
    "            \n",
    "            if not text:  # Lewati teks kosong\n",
    "                results.append({\n",
    "                    'text': text,\n",
    "                    'sentiment': \"unknown\",\n",
    "                    'confidence': 0.0\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Tokenisasi teks\n",
    "            encoded = tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # Model memprediksi\n",
    "            outputs = model(encoded[\"input_ids\"], attention_mask=encoded[\"attention_mask\"])\n",
    "            predictions = F.softmax(outputs.logits, dim=1)\n",
    "            predicted_label = torch.argmax(predictions, dim=1).item()\n",
    "            \n",
    "            # Ambil confidence score\n",
    "            confidence = predictions[0][predicted_label].item()\n",
    "            \n",
    "            # Mapping hasil prediksi ke label\n",
    "            sentiment = label_map.get(predicted_label, \"unknown\")\n",
    "            \n",
    "            # Menambahkan hasil ke dalam list\n",
    "            results.append({\n",
    "                'text': text,\n",
    "                'sentiment': sentiment,\n",
    "                'confidence': confidence\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "columns_to_process = ['OPEN QUESTION 1']\n",
    "\n",
    "all_data_idi_df['Text'] = all_data_idi_df[columns_to_process].fillna(\"\").apply(lambda row: \" \".join(row), axis=1)\n",
    "\n",
    "results = predict_sentiment(all_data_idi_df['Text'].tolist())\n",
    "\n",
    "all_data_idi_df.loc[:, 'Label'] = results['sentiment']\n",
    "all_data_idi_df.loc[:, 'Confidence'] = results['confidence']\n",
    "\n",
    "# Menampilkan hasil\n",
    "print(\"\\nSample of labeled data:\")\n",
    "print(all_data_idi_df[['OPEN QUESTION 1','Label', 'Confidence']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_idi_df.to_csv('data/hasil/main_data_17_OQ1.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          ID BIDANG SATKER (AKRONIM) JENIS SURVEI  \\\n",
      "0       DATABASE INTERNAL_23     MS             DPSI     INTERNAL   \n",
      "1       DATABASE INTERNAL_24     MS             DPSI     INTERNAL   \n",
      "2       DATABASE INTERNAL_26     MS             DPSI     INTERNAL   \n",
      "3       DATABASE INTERNAL_28     MS             DPSI     INTERNAL   \n",
      "4       DATABASE INTERNAL_30     MS             DPSI     INTERNAL   \n",
      "...                      ...    ...              ...          ...   \n",
      "2916  DATABASE INTERNAL_9528     MS             DPSU     INTERNAL   \n",
      "2917  DATABASE INTERNAL_9537     MS             DPSU     INTERNAL   \n",
      "2918  DATABASE INTERNAL_9540     MS             DPSU     INTERNAL   \n",
      "2919  DATABASE INTERNAL_9637    ARK             DPAI     INTERNAL   \n",
      "2920  DATABASE INTERNAL_9647    ARK             DPAI     INTERNAL   \n",
      "\n",
      "      TIPE QUESTION INSTITUSI / PERSEORANGAN/ASAL SATKER       RESPOND  \\\n",
      "0       DIRECT DPSI                                 DPAI  SUDAH DI ISI   \n",
      "1       DIRECT DPSI                                 DPAI  SUDAH DI ISI   \n",
      "2       DIRECT DPSI                                 DPAI  SUDAH DI ISI   \n",
      "3       DIRECT DPSI                                 DPAI  SUDAH DI ISI   \n",
      "4       DIRECT DPSI                                 DPAI  SUDAH DI ISI   \n",
      "...             ...                                  ...           ...   \n",
      "2916  INDIRECT DPSU                                 DRPK  SUDAH DI ISI   \n",
      "2917  INDIRECT DPSU                                 KODS  SUDAH DI ISI   \n",
      "2918    DIRECT DPSU                                 DINP  SUDAH DI ISI   \n",
      "2919    DIRECT DPAI                                  ADK  SUDAH DI ISI   \n",
      "2920    DIRECT DPAI                                 DKKL  SUDAH DI ISI   \n",
      "\n",
      "                                      LINK SURVEYMONKEY       TOKEN  \\\n",
      "0       Internal 2 (Direct DOSB & Direct DPSI, 129_173)  Token 0128   \n",
      "1     Internal 1 (Direct DPSI & Indirect DOSB, 253_2...  Token 0252   \n",
      "2     Internal 1 (Direct DPSI & Indirect DOSB, 253_2...  Token 0252   \n",
      "3     Internal 1 (Direct DPSI & Indirect DOSB, 253_2...  Token 0252   \n",
      "4     Internal 1 (Direct DPSI & Indirect DOSB, 253_2...  Token 0252   \n",
      "...                                                 ...         ...   \n",
      "2916                                              LOGIC  Token 0086   \n",
      "2917                                              LOGIC  Token 0116   \n",
      "2918                                              LOGIC  Token 0035   \n",
      "2919                                              LOGIC  Token 0130   \n",
      "2920                                              LOGIC  Token 0074   \n",
      "\n",
      "                    NAMA PIC/RESPONDEN  ... INTEREST  KATEGORI  \\\n",
      "0          Albertus Widjono Pratijakso  ...     HIGH    PLAYER   \n",
      "1     Glendy Mario Constantine Walujan  ...     HIGH    PLAYER   \n",
      "2                      Tengku Faradina  ...     HIGH    PLAYER   \n",
      "3                     Sefrina Widyanti  ...     HIGH    PLAYER   \n",
      "4                 Aditya Arief Nugraha  ...     HIGH    PLAYER   \n",
      "...                                ...  ...      ...       ...   \n",
      "2916                  Retno Woelandari  ...     high  Subjects   \n",
      "2917           Kristrianti Puji Rahayu  ...     high  Subjects   \n",
      "2918               Rachman Arief Bakry  ...     high    Player   \n",
      "2919         Sophia Issabella Watimena  ...     High    Player   \n",
      "2920                      Aman Santosa  ...     High    Player   \n",
      "\n",
      "                      Dataset RESOURCE PERCEPTION PERFORMANCE DELIVERY  \\\n",
      "0           Database Internal         5,333333333          5,285714286   \n",
      "1           Database Internal         5,666666667                    6   \n",
      "2           Database Internal                   5                    5   \n",
      "3           Database Internal                   6          5,285714286   \n",
      "4           Database Internal         5,666666667                    6   \n",
      "...                       ...                 ...                  ...   \n",
      "2916  DATABASE LOGIC INTERNAL                   0                    0   \n",
      "2917  DATABASE LOGIC INTERNAL                   0                    0   \n",
      "2918  DATABASE LOGIC INTERNAL                   5                    5   \n",
      "2919  DATABASE LOGIC INTERNAL                   -                    -   \n",
      "2920  DATABASE LOGIC INTERNAL                   5          4,833333333   \n",
      "\n",
      "                                        OPEN QUESTION 1  \\\n",
      "0     Sdh sangat bagus hanya banyak terkendala krn k...   \n",
      "1                                           sangat baik   \n",
      "2                               sudah baik, pertahankan   \n",
      "3                        Sejauh ini baik dan responsif.   \n",
      "4     Pengelolaan sistem informasi oleh DPSI OJK tel...   \n",
      "...                                                 ...   \n",
      "2916                                                  0   \n",
      "2917               mempermudah monev sipo bagi pengawas   \n",
      "2918  Untuk menyediakan alat bantu (aplikasi) atau k...   \n",
      "2919                                                  0   \n",
      "2920                                                  -   \n",
      "\n",
      "                                        OPEN QUESTION 2  \\\n",
      "0     fungsi pengelolaan informasi harus imbang anta...   \n",
      "1                                                     -   \n",
      "2     sudah cukup baik pertahankan kinerja yang suda...   \n",
      "3     Agar terdapat no wa helpdesk per masing-masing...   \n",
      "4     agar dapat setiap pegawai di fasilitas dengan ...   \n",
      "...                                                 ...   \n",
      "2916                                                  0   \n",
      "2917                                                  0   \n",
      "2918                                                  0   \n",
      "2919                                                  0   \n",
      "2920                                                  -   \n",
      "\n",
      "                                                   Text          Label  \\\n",
      "0     Sdh sangat bagus hanya banyak terkendala krn k...         setuju   \n",
      "1                                           sangat baik         setuju   \n",
      "2                               sudah baik, pertahankan   cukup setuju   \n",
      "3                        Sejauh ini baik dan responsif.   cukup setuju   \n",
      "4     Pengelolaan sistem informasi oleh DPSI OJK tel...  kurang setuju   \n",
      "...                                                 ...            ...   \n",
      "2916                                                  0         setuju   \n",
      "2917               mempermudah monev sipo bagi pengawas         setuju   \n",
      "2918  Untuk menyediakan alat bantu (aplikasi) atau k...         setuju   \n",
      "2919                                                  0         setuju   \n",
      "2920                                                  -         setuju   \n",
      "\n",
      "     Confidence  \n",
      "0      0.222106  \n",
      "1      0.199094  \n",
      "2      0.208029  \n",
      "3      0.213246  \n",
      "4      0.229381  \n",
      "...         ...  \n",
      "2916   0.226969  \n",
      "2917   0.214175  \n",
      "2918   0.241421  \n",
      "2919   0.226969  \n",
      "2920   0.239714  \n",
      "\n",
      "[2921 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_data_idi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Menyimpan data ke file CSV\n",
    "# output_file = \"./data/hasil/all_data_idi_ss.csv\"\n",
    "# all_data_idi_df.to_csv(output_file, index=False, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# print(f\"Data berhasil disimpan ke {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SAVE MODEL\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# # Ganti model_name dengan model IndoBERT\n",
    "# model_name = \"indobenchmark/indobert-base-p1\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     model_name,\n",
    "#     num_labels=6  # Sesuaikan jumlah label\n",
    "# )\n",
    "\n",
    "# # Menyimpan model dan tokenizer ke direktori\n",
    "# model_save_path = './saved_model'\n",
    "# tokenizer.save_pretrained(model_save_path)\n",
    "# model.save_pretrained(model_save_path)\n",
    "\n",
    "# print(f\"Model dan tokenizer berhasil disimpan di {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #LOAD MODEL\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# # Path ke model yang disimpan\n",
    "# model_save_path = './saved_model'\n",
    "\n",
    "# # Memuat model dan tokenizer dari path yang telah disimpan\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_save_path)\n",
    "\n",
    "# print(f\"Model dan tokenizer berhasil dimuat dari {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Label  Count\n",
      "0               setuju   1760\n",
      "1        kurang setuju    768\n",
      "2         cukup setuju    275\n",
      "3        sangat setuju    116\n",
      "4  sangat tidak setuju      2\n"
     ]
    }
   ],
   "source": [
    "label_counts = all_data_idi_df['Label'].value_counts()\n",
    "\n",
    "label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "label_summary.columns = ['Label', 'Count']\n",
    "print(label_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs('data/hasil', exist_ok=True)\n",
    "# all_data_idi_df.to_csv('data/hasil/labeled.csv', index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from textblob import TextBlob\n",
    "# #VALIDASI\n",
    "\n",
    "# file_path = 'data/hasil/main_data_REV.csv'\n",
    "\n",
    "# # Load dataset\n",
    "# data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# data_copy = data.copy()\n",
    "\n",
    "# # Fungsi untuk melakukan labeling berdasarkan polaritas\n",
    "# def assign_label(text):\n",
    "#     # Membuat objek TextBlob dari teks\n",
    "#     blob = TextBlob(text)\n",
    "    \n",
    "#     # Menghitung polaritas\n",
    "#     polarity = blob.sentiment.polarity\n",
    "    \n",
    "#     # Menentukan label berdasarkan polaritas\n",
    "#     if polarity > 0.5:\n",
    "#         return \"Sangat Setuju\"\n",
    "#     elif polarity > 0:\n",
    "#         return \"Setuju\"\n",
    "#     elif polarity == 0:\n",
    "#         return \"Cukup Setuju\"\n",
    "#     elif polarity < -0.5:\n",
    "#         return \"Sangat Tidak Setuju\"\n",
    "#     else:\n",
    "#         return \"Kurang Setuju\"\n",
    "\n",
    "\n",
    "# # # Membaca file JSON yang berisi mapping\n",
    "# with open('mapping.json', 'r') as file:\n",
    "#     text_mapping = json.load(file)\n",
    "\n",
    "\n",
    "# # # Fungsi untuk menentukan label berdasarkan kata-kata dalam 'Combined_Text'\n",
    "# def map_combined_text_to_label(text):\n",
    "#     # Iterasi untuk mencari kata kunci dalam text\n",
    "#     for keyword, label in text_mapping.items():\n",
    "#         if keyword in text.lower():  # Mengabaikan kapitalisasi\n",
    "#             return label\n",
    "#     return 'setuju'  # Jika tidak ada kata kunci yang ditemukan\n",
    "\n",
    "# # Terapkan fungsi ke kolom 'Combined_Text' untuk membuat kolom 'Label'\n",
    "# data_copy['New_Label'] = data_copy['Text'].apply(assign_label)\n",
    "\n",
    "# # Tampilkan dataset yang sudah dimodifikasi\n",
    "# data_copy['Label'] = data_copy['New_Label'].combine_first(data_copy['Label'])\n",
    "\n",
    "# # Simpan dataset yang sudah dimodifikasi\n",
    "# data_copy.to_csv('data/hasil/validated_dataset_new.csv', index=False, sep=';')\n",
    "\n",
    "# # Menampilkan statistik label setelah perubahan\n",
    "# label_counts = data_copy['Label'].value_counts()\n",
    "# label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "# label_summary.columns = ['Label', 'Count']\n",
    "\n",
    "# label_map = {\n",
    "#     1: \"sangat tidak setuju\",\n",
    "#     2: \"tidak setuju\",\n",
    "#     3: \"kurang setuju\",\n",
    "#     4: \"cukup setuju\",\n",
    "#     5: \"setuju\",\n",
    "#     6: \"sangat setuju\"\n",
    "# }\n",
    "\n",
    "# reverse_label_map = {v: k for k, v in label_map.items()}  \n",
    "\n",
    "# data_copy['Label_Index'] = data_copy['Label'].map(reverse_label_map)\n",
    "\n",
    "# def calculate_weight(index):\n",
    "#     if index == 1:\n",
    "#         return 1\n",
    "#     elif 1.1 <= index <= 2.9:\n",
    "#         return 2.95\n",
    "#     elif 3 <= index <= 3.9:\n",
    "#         return 5.9\n",
    "#     elif 4 <= index <= 6:\n",
    "#         return 6\n",
    "#     else:\n",
    "#         return None  \n",
    "\n",
    "# data_copy['NILAI_SENTIMEN'] = data_copy['Label_Index'].apply(calculate_weight)\n",
    "\n",
    "# # print(data_copy)\n",
    "\n",
    "\n",
    "# print(data_copy[['Label','NILAI_SENTIMEN']])\n",
    "# data_copy.to_csv('data/hasil/main_data_REVREV.csv', index=False, sep=';')\n",
    "\n",
    "# label_counts = data_copy['Label'].value_counts()\n",
    "# label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "# label_summary.columns = ['Label', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Label  NILAI_SENTIMEN\n",
      "0     sangat setuju             6.0\n",
      "1     sangat setuju             6.0\n",
      "2            setuju             6.0\n",
      "3            setuju             6.0\n",
      "4            setuju             6.0\n",
      "...             ...             ...\n",
      "2916         setuju             6.0\n",
      "2917         setuju             6.0\n",
      "2918         setuju             6.0\n",
      "2919         setuju             6.0\n",
      "2920         setuju             6.0\n",
      "\n",
      "[2921 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# TODO: ini yang bener\n",
    "\n",
    "import json\n",
    "#VALIDASI\n",
    "\n",
    "file_path = 'data/hasil/main_data_17_OQ1.csv'\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Membaca file JSON yang berisi mapping\n",
    "with open('mapping.json', 'r') as file:\n",
    "    text_mapping = json.load(file)\n",
    "    \n",
    "# data_copy['Text'] = data_copy['Text'].str.lower()\n",
    "\n",
    "# Fungsi untuk menentukan label berdasarkan kata-kata dalam 'Combined_Text'\n",
    "def map_combined_text_to_label(text):\n",
    "    # Iterasi untuk mencari kata kunci dalam text\n",
    "    for keyword, label in text_mapping.items():\n",
    "        if keyword in text.lower():  # Mengabaikan kapitalisasi\n",
    "            return label\n",
    "    return 'setuju'  # Jika tidak ada kata kunci yang ditemukan\n",
    "\n",
    "# Terapkan fungsi ke kolom 'Combined_Text' untuk membuat kolom 'Label'\n",
    "data_copy['New_Label'] = data_copy['Text'].apply(map_combined_text_to_label)\n",
    "\n",
    "# Tampilkan dataset yang sudah dimodifikasi\n",
    "data_copy['Label'] = data_copy['New_Label'].combine_first(data_copy['Label'])\n",
    "\n",
    "# Simpan dataset yang sudah dimodifikasi\n",
    "data_copy.to_csv('data/hasil/validated_dataset_new.csv', index=False, sep=';')\n",
    "\n",
    "# Menampilkan statistik label setelah perubahan\n",
    "label_counts = data_copy['Label'].value_counts()\n",
    "label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "label_summary.columns = ['Label', 'Count']\n",
    "\n",
    "label_map = {\n",
    "    1: \"sangat tidak setuju\",\n",
    "    2: \"tidak setuju\",\n",
    "    3: \"kurang setuju\",\n",
    "    4: \"cukup setuju\",\n",
    "    5: \"setuju\",\n",
    "    6: \"sangat setuju\"\n",
    "}\n",
    "\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}  \n",
    "\n",
    "data_copy['Label_Index'] = data_copy['Label'].map(reverse_label_map)\n",
    "\n",
    "def calculate_weight(index):\n",
    "    if index == 1:\n",
    "        return 1\n",
    "    elif 1.1 <= index <= 2.9:\n",
    "        return 2.95\n",
    "    elif 3 <= index <= 3.9:\n",
    "        return 5.9\n",
    "    elif 4 <= index <= 6:\n",
    "        return 6\n",
    "    else:\n",
    "        return None  \n",
    "\n",
    "data_copy['NILAI_SENTIMEN'] = data_copy['Label_Index'].apply(calculate_weight)\n",
    "\n",
    "# print(data_copy)\n",
    "\n",
    "\n",
    "print(data_copy[['Label','NILAI_SENTIMEN']])\n",
    "data_copy.to_csv('data/hasil/main_data_17_OQ1_dashboard.csv', index=False, sep=';')\n",
    "\n",
    "label_counts = data_copy['Label'].value_counts()\n",
    "label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "label_summary.columns = ['Label', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Label  Count\n",
      "0               setuju   2393\n",
      "1        sangat setuju    324\n",
      "2         cukup setuju    140\n",
      "3         tidak setuju     63\n",
      "4  sangat tidak setuju      1\n"
     ]
    }
   ],
   "source": [
    "label_counts = data_copy['Label'].value_counts()\n",
    "\n",
    "label_summary = pd.DataFrame(label_counts).reset_index()\n",
    "label_summary.columns = ['Label', 'Count']\n",
    "print(label_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
